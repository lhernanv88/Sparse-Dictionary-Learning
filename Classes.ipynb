{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def get_ith_patch(large_shape, patch_shape, i):\n",
    "    # How many patches can we fit in this large array?\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "\n",
    "    # What are the coordinates of the starting pixel of the ith patch?\n",
    "    patch_index = np.unravel_index(i, patch_index_shape)\n",
    "\n",
    "    # Get the indices for the pixels in the ith patch\n",
    "    patch_indices = tuple(slice(start, start + size) for start, size in zip(patch_index, patch_shape))\n",
    "\n",
    "    return patch_indices\n",
    "\n",
    "def get_num_patches(large_shape, patch_shape):\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "    return patch_index_shape.prod()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.seed = 1 # A random seed which will be updated after every use. It is there to ensure reproducibility\n",
    "        self.paths = [] # A list of the paths where original images/signals are stored\n",
    "\n",
    "    def add_path(self, path):\n",
    "        self.paths.append(path)\n",
    "\n",
    "    def set_paths(self, paths):\n",
    "        self.paths = paths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "\n",
    "#def signal_to_vec(self, signal):\n",
    "\n",
    "#def vec_to_signal(self, vec):\n",
    "\n",
    "def sample(self, N):\n",
    "\n",
    "    # Divide the number of samples requested evenly amongst each original full image\n",
    "    j = 0\n",
    "    r = N % len(self.paths)\n",
    "    d = self.patch_shape.prod()\n",
    "    Y = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "    for i, path in enumerate(self.paths):\n",
    "        img = cv2.imread(path)\n",
    "        large_shape = img.shape\n",
    "\n",
    "        for _ in range(N // len(self.paths)):\n",
    "\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "            Y[:, j] = img[patch].flatten().ravel()\n",
    "            j+=1\n",
    "        if i<r:\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "            Y[:, j] = img[patch]\n",
    "            j+=1\n",
    "\n",
    "    return Y\n",
    "\n",
    "def sample_noise(self, N, add_noise=False, noise_std=10):\n",
    "    \"\"\"\n",
    "    Randomly sample patches from images in self.paths, with the option to add Gaussian noise.\n",
    "    Args:\n",
    "        N: int, number of patches to sample\n",
    "        add_noise: bool, whether to add Gaussian noise to the patches\n",
    "        noise_std: float, standard deviation of the Gaussian noise\n",
    "    Returns:\n",
    "        Y: np.array, of shape (d, N), where d is the product of the patch dimensions, containing the sampled patches\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the product of the patch dimensions\n",
    "    d = self.patch_shape.prod()\n",
    "\n",
    "    # Initialize an array to hold the sampled patches\n",
    "    Y = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "    def get_sample(img, add_noise):\n",
    "        \"\"\"\n",
    "        Helper function to get a single patch sample from an image.\n",
    "        Args:\n",
    "            img: np.array, representing an image\n",
    "            add_noise: bool, whether to add Gaussian noise to the patch\n",
    "        Returns:\n",
    "            sample: np.array, of shape (d,), representing the sampled patch\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a random patch from the image\n",
    "        patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "        sample = img[patch].flatten()\n",
    "\n",
    "        # Add Gaussian noise to the patch, if specified\n",
    "        if add_noise:\n",
    "            noise = np.zeros_like(sample)\n",
    "            cv2.randn(noise, 0, noise_std)\n",
    "            sample = np.clip(sample + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    # Divide the number of samples requested evenly amongst each original full image\n",
    "    j = 0\n",
    "    r = N % len(self.paths)\n",
    "\n",
    "    for i, path in enumerate(self.paths):\n",
    "        # Read in the image and get its shape\n",
    "        img = cv2.imread(path)\n",
    "        large_shape = img.shape\n",
    "\n",
    "        # Get the number of patches that can be extracted from the image\n",
    "        num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "\n",
    "        # Sample patches from the image\n",
    "        for _ in range(N // len(self.paths)):\n",
    "            sample = get_sample(img, add_noise)\n",
    "            Y[:, j] = sample\n",
    "            j += 1\n",
    "\n",
    "        # If there are any remaining samples, sample them from the current image\n",
    "        if i < r:\n",
    "            sample = get_sample(img, add_noise)\n",
    "            Y[:, j] = sample\n",
    "            j += 1\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "Sampler.sample = sample\n",
    "Sampler.sample_noise = sample_noise\n",
    "\n",
    "\n",
    "#def add_noise(self, signal):\n",
    "\n",
    "#def drop_pixels(self, signal):\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "sam = Sampler()\n",
    "sam.add_path('dinner.jpg')\n",
    "sam.patch_shape = np.array([1000,1000,3])\n",
    "Y = sam.sample_noise(3, add_noise=True, noise_std=1000)\n",
    "cv2.imshow('test', Y[:,0].reshape(sam.patch_shape))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_sparse_rep_MP(Y, D, L):\n",
    "    \"\"\"\n",
    "    :param Y: This is a (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is a (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional vectors. Each column vector must have already been normalized.\n",
    "    :param L: This is an integer satisfying 0 < L <= K representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Runs in O( N K L ) time.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    assert d == d1 # Make sure the dimensions match up\n",
    "\n",
    "    A = np.zeros((K, N)) # Get our Sparse Representation Matrix\n",
    "\n",
    "    for j in range(N):  # Iterate over all of the N given signal vectors Y[:,j].\n",
    "\n",
    "        alpha = np.zeros(K)  # Initialize the sparse representation vector (will be a column vector in A)\n",
    "        r_vec = Y[:, j] - np.dot(D, alpha)  # Initialize the \"residual\" vector\n",
    "\n",
    "        for i in range(L): # Repeat until we utilize L atoms, or no more are needed\n",
    "            position_coeff_error = []\n",
    "\n",
    "            for k in range(K): # Find the best atom, D[:,k]\n",
    "\n",
    "                atom = D[:, k]\n",
    "\n",
    "                # Project the residual vector r_vec down to the linear subspace defined by the atom\n",
    "                coeff = np.inner(r_vec, atom)\n",
    "                error = np.linalg.norm(r_vec - coeff * atom)\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2]) # Find the atom whose linear subspace is closest to the residual vector r_vec\n",
    "\n",
    "            if np.abs(coeff) < 1e-6: #If the coefficient is too small, we don't add it and instead end the iteration\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                alpha[position] += coeff # Update the sparse representation vector, alpha\n",
    "                r_vec -= coeff * D[:, position] # Update the residual vector, r_vec\n",
    "\n",
    "        A[:, j] = alpha # Insert the sparse representation vector alpha into the matrix A\n",
    "\n",
    "    return A\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "def find_sparse_rep_OMP(Y, D, L):\n",
    "    \"\"\"\n",
    "    Find the sparse representation of the given signals Y over the dictionary D using the Orthogonal Matching Pursuit\n",
    "    algorithm.\n",
    "    Runs in O( N K L^2 ) time.\n",
    "\n",
    "    :param Y: A (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: A (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param L: An integer representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "\n",
    "    # Initialize the sparse representation matrix A\n",
    "    A = np.zeros((K, N))\n",
    "\n",
    "    # Iterate over all of the N given signal vectors Y[:,j].\n",
    "    for j in range(N):\n",
    "\n",
    "        # Initialize the set of indices for the selected atoms\n",
    "        idx_set = set()\n",
    "\n",
    "        # Repeat until we utilize L atoms, or no more are needed\n",
    "        for i in range(L):\n",
    "\n",
    "            # Find the remaining unused atoms\n",
    "            remaining_atoms = set(range(K)).difference(idx_set)\n",
    "\n",
    "            # Initialize a list to store the coefficients and errors for each candidate atom\n",
    "            position_coeff_error = []\n",
    "\n",
    "            # Iterate over the remaining unused atoms and calculate the projection error for each\n",
    "            for k in remaining_atoms:\n",
    "                # Create the subspace basis from the remaining unused atoms plus the current candidate atom\n",
    "                subspace_basis = D[:, list(idx_set) + [k]]\n",
    "\n",
    "                # Solve for the coefficients of the projection\n",
    "                coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "                # Calculate the projected vector\n",
    "                projected = np.dot(subspace_basis, coeff)\n",
    "\n",
    "                # Calculate the error between the original signal and the projection\n",
    "                error = np.linalg.norm(Y[:, j] - projected)\n",
    "\n",
    "                # Store the position, coefficients, and error in the list\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            # Select the candidate atom with the minimum projection error\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2])\n",
    "\n",
    "            # Add the selected atom to the set of indices for the selected atoms\n",
    "            idx_set.add(position)\n",
    "\n",
    "        # Create the final subspace basis from the selected atoms\n",
    "        subspace_basis = D[:, list(idx_set)]\n",
    "\n",
    "        # Solve for the coefficients of the sparse representation using the selected atoms\n",
    "        coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "        # Initialize the sparse representation vector alpha\n",
    "        alpha = np.zeros(K)\n",
    "\n",
    "        # Insert the computed coefficients into the sparse representation vector alpha\n",
    "        for position, index in enumerate(idx_set):\n",
    "            alpha[index] = coeff[position]\n",
    "\n",
    "        # Insert the sparse representation vector alpha into the matrix A\n",
    "        A[:, j] = alpha\n",
    "\n",
    "        # Return the matrix of sparse representations\n",
    "    return A\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "class DictionaryLearner:\n",
    "\n",
    "    def __init__(self, L, K):\n",
    "        self.L = L # The maximum number of atoms a sparse representation can use\n",
    "        self.K = K # The size of the dictionary\n",
    "        self.Dictionary = None # The initial guesses for the dictionary\n",
    "\n",
    "    def set_initial_dictionary(self, D):\n",
    "        self.Dictionary = D\n",
    "\n",
    "    def select_algorithm(self, algo):\n",
    "        if algo == 'MP':\n",
    "            self.sparse_rep = find_sparse_rep_MP\n",
    "        elif algo == 'OMP':\n",
    "            self.sparse_rep = sparse_rep = find_sparse_rep_OMP\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def update_dictionary_kSVD(Y, D, A):\n",
    "    \"\"\"\n",
    "    Update the dictionary using the k-SVD algorithm. This\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "\n",
    "    :return: (D, A), where D is updated and optimized to the given  a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    (K1, N1) = A.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "    assert K == K1\n",
    "    assert N == N1\n",
    "\n",
    "    # Iterate over every atom in the dictionary\n",
    "    for k in range(K):\n",
    "        # Find the signal vectors, Y[:,j], whose sparse representation, A[:,j], have a non-zero entry in the k^th position. That is, they use the k^th atom.\n",
    "        non_zero_indices = np.nonzero(A[k, :])[0]\n",
    "\n",
    "        # Get the k^th \"error matrix\"\n",
    "        E = Y - np.dot(D, A) + np.outer(D[:, k], A[k, :])\n",
    "\n",
    "        # Restrict the matrix to only those non-zero values. The resulting matrix should be KxL\n",
    "        E = E[:, non_zero_indices]\n",
    "\n",
    "        # Do the SVD (Singular Value Decomposition) step to the KxL matrix E\n",
    "        U, S, V = np.linalg.svd(E, full_matrices=False)\n",
    "\n",
    "        # Update the k^th atom, D[:, k], and the k^th coefficients in the sparse representation, A[k, :].\n",
    "        # Note: The k-SVD algorithm also converges when run in parallel, only updating the matrix D at the end. However running the algorithm in series, updating the atoms and coefficients after each step, produces more robust results and typically requires more than four times as long to converge.\n",
    "        D[:, k] = U[:, 0]\n",
    "        A[k, non_zero_indices] = S[0] * V[0, :]\n",
    "\n",
    "    return (D, A)\n",
    "\n",
    "def update_dictionary(self, Y, A):\n",
    "    return update_dictionary_kSVD(Y, self.D, A)\n",
    "\n",
    "DictionaryLearner.update_dictionary = update_dictionary\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_dictionary() missing 2 required positional arguments: 'Y' and 'A'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\818255142.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mlearner\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDictionaryLearner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mselect_algorithm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'MP'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate_dictionary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: update_dictionary() missing 2 required positional arguments: 'Y' and 'A'"
     ]
    }
   ],
   "source": [
    "learner = DictionaryLearner(5, 10)\n",
    "learner.select_algorithm('MP')\n",
    "learner.update_dictionary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sparse_dictionary_learning(Y, K, L, iters=10, D_initial=None, algo='OMP', samples=100, with_errors=False):\n",
    "    \"\"\"\n",
    "    This algorithm finds a (d x K) matrix D (the dictionary) and a (K x N) matrix A (the sparse representation) which minimise the L2 distance between Y and D A, ie, minimise ||Y - D A ||, subject to the constraint that each column of A has at most L non-zero elements.\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param K: An integer representing the size of the dictionary.\n",
    "    :param L: An integer representing the maximum number of \"atoms\", D[:, k], in the dictionary that each sparse representation vector, A[:, i], can use.\n",
    "\n",
    "    Note: This algorithm is written under the assumption that: 0 < L < d < K < N\n",
    "\n",
    "    :param D_initial: This is the initial guess for the (d x N) matrix D. If not None, the columns of this matrix must be unit length.\n",
    "    :param algo: This is a string defining the sparse representation algorithm. Either algo = 'OMP' for Orhtogonal Matching Pursuit, or algo = 'MP' for Matching Pursuit.\n",
    "    :param iters: The number of iterations this will run for\n",
    "    :param with_errors: A boolean which determines if the output includes the list of the error values at each step of the iteration.\n",
    "    :param samples: This tells us the number of random samples to take from the training data Y at each step\n",
    "\n",
    "    :return: (D, A, errors)\n",
    "        D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors.\n",
    "        A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "        errors: This is an optional output. It is the list of the error values at each step of the iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    Y_full = Y\n",
    "\n",
    "    # Get Initial D\n",
    "    if D_initial == None:\n",
    "        D = Y[:, random.sample(range(N), k=K)]\n",
    "        D = D / np.linalg.norm(D, axis=0)\n",
    "\n",
    "    # Get the correct algorithm\n",
    "    if algo == 'OMP':\n",
    "        sparse_rep = find_sparse_rep_OMP\n",
    "    elif algo == 'MP':\n",
    "        sparse_rep = find_sparse_rep\n",
    "\n",
    "    # Initialize the list of error values\n",
    "    errors = []\n",
    "\n",
    "    for step in range(iters):\n",
    "        Y = Y_full[:, random.sample(range(len(Y[0])), k=samples)]\n",
    "        A = sparse_rep(Y, D, L)\n",
    "        D = update_dictionary_kSVD(Y, D, A)\n",
    "\n",
    "        if with_errors:\n",
    "            errors.append(np.linalg.norm(Y - np.dot(D, A)))\n",
    "\n",
    "    A = sparse_rep(Y_full, D, L)\n",
    "\n",
    "    if with_errors:\n",
    "        return (D, A, errors)\n",
    "    else:\n",
    "        return (D, A)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def dictionary_learning(self, Y, )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\1662819167.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mlearner\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDictionaryLearner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mselect_alorithm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'MP'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_rep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "learner = DictionaryLearner(5, 10)\n",
    "learner.select_algorithm('MP')\n",
    "learner.sparse_rep(Y, D, L)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([1,2,3]).prod()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.05992862, -0.01217082, -0.01924014,  0.0360319 , -0.00776401,\n        -0.000524  ,  0.14573281,  0.07641563],\n       [-0.18572422,  0.14079179, -0.15667047,  0.2305574 ,  0.04327394,\n         0.03192766, -0.03948167,  0.15574063],\n       [-0.18094431,  0.03454035,  0.05829101, -0.04971573, -0.02696382,\n        -0.13489656,  0.09165429, -0.09473357],\n       [-0.07280259, -0.0614746 , -0.0841094 , -0.10062964,  0.03619999,\n        -0.07039527,  0.01951222,  0.04212763],\n       [-0.01718095, -0.02416182,  0.14357363, -0.06101194, -0.0752874 ,\n         0.05919809,  0.18025043, -0.06981907],\n       [ 0.04946283, -0.00567512, -0.03728039, -0.01652367, -0.06759748,\n        -0.02250607, -0.03298199, -0.02765604],\n       [ 0.06038713, -0.06817364,  0.05721233,  0.06235531,  0.09877378,\n         0.06874567,  0.0978708 ,  0.12555003],\n       [ 0.07603313, -0.04014293, -0.1132591 ,  0.18838865, -0.01803408,\n         0.15091138,  0.0526451 , -0.10075915]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 0.1, np.array([8,8]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\2486947686.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
