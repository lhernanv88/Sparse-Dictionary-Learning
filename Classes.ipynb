{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sparse Dictionary Learning\n",
    "\n",
    "This is the notebook where I construct the classes and functions used in sparse dictionary learning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_ith_patch(large_shape, patch_shape, i):\n",
    "    # How many patches can we fit in this large array?\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "\n",
    "    # What are the coordinates of the starting pixel of the ith patch?\n",
    "    patch_index = np.unravel_index(i, patch_index_shape)\n",
    "\n",
    "    # Get the indices for the pixels in the ith patch\n",
    "    patch_indices = tuple(slice(start, start + size) for start, size in zip(patch_index, patch_shape))\n",
    "\n",
    "    return patch_indices\n",
    "\n",
    "def get_num_patches(large_shape, patch_shape):\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "    return patch_index_shape.prod()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if (img[:,:,0] == img[:,:,1]).all():\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Sampler\n",
    "\n",
    "It quickly became clear that I will have far more training data than I can possibly utilize in each iteration. So I will randomly sample the training data. This sampler will eventually be passed as an attribute of objects in another class."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, paths = [], num_samples = 300, patch_shape = np.array([8,8,3])):\n",
    "        #self.seed = 1 # A random seed which will be updated after every use. It is there to ensure reproducibility\n",
    "        self.paths = paths # A list of the paths where original images/signals are stored\n",
    "        self.add_filter(None)\n",
    "        self.num_samples = num_samples\n",
    "        self.patch_shape = patch_shape\n",
    "\n",
    "    def set_patch_shape(self, patch_shape):\n",
    "        self.patch_shape = patch_shape\n",
    "\n",
    "    def set_num_samples(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def add_path(self, path):\n",
    "        self.paths.append(path)\n",
    "\n",
    "    def set_paths(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def add_filter(self, filter, std = 10):\n",
    "\n",
    "        if filter == None:\n",
    "            foo = lambda x: x\n",
    "            self.filter = foo\n",
    "\n",
    "        elif filter == 'noise':\n",
    "\n",
    "            def filter(sample):\n",
    "\n",
    "                noise = np.zeros_like(sample)\n",
    "                cv2.randn(noise, 0, std)\n",
    "                sample = np.clip(sample + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "                return sample\n",
    "            self.filter = filter\n",
    "\n",
    "    def sample(self, N = None):\n",
    "        \"\"\"\n",
    "        A function which returns N samples. It returns a pair of matrices (Y_corrupted, Y_original).\n",
    "\n",
    "        :param N:\n",
    "        :param two_copies:\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def get_sample(img1, img2):\n",
    "            \"\"\"\n",
    "            Helper function to get a single patch sample from an image.\n",
    "            Args:\n",
    "                img: np.array, representing an image\n",
    "                add_noise: bool, whether to add Gaussian noise to the patch\n",
    "            Returns:\n",
    "                sample: np.array, of shape (d,), representing the sampled patch\n",
    "            \"\"\"\n",
    "\n",
    "            # Get a random patch from the image\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches-1))\n",
    "\n",
    "            return (img1[patch].flatten(), img2[patch].flatten())\n",
    "\n",
    "        # Get the number of samples\n",
    "        if N == None:\n",
    "            N = self.num_samples\n",
    "\n",
    "        # Get the product of the patch dimensions\n",
    "        d = self.patch_shape.prod()\n",
    "\n",
    "        # Initialize an array to hold the sampled patches\n",
    "        Y = np.zeros([d, N], dtype=np.uint8)\n",
    "        Y_orig = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "        # Divide the number of samples requested evenly amongst each original full image\n",
    "        j = 0\n",
    "        r = N % len(self.paths)\n",
    "\n",
    "        for i, path in enumerate(self.paths):\n",
    "\n",
    "            # Read in the image, apply the filter, and if nessisary preserve the original copy\n",
    "            img2 = load_image(path)\n",
    "            img1 = self.filter(img2)\n",
    "\n",
    "            # Get the shape of the image\n",
    "            large_shape = img1.shape\n",
    "\n",
    "            # Get the number of patches that can be extracted from the image\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "\n",
    "            # Sample patches from the image\n",
    "            for _ in range(N // len(self.paths)):\n",
    "                (corrupted_sample, original_sample) = get_sample(img1, img2)\n",
    "                Y[:, j] = corrupted_sample\n",
    "                Y_orig[:, j] = original_sample\n",
    "                j += 1\n",
    "\n",
    "            # If there are any remaining samples, sample them from the current image\n",
    "            if i < r:\n",
    "                (corrupted_sample, original_sample) = get_sample(img1, img2)\n",
    "                Y[:, j] = corrupted_sample\n",
    "                Y_orig[:, j] = original_sample\n",
    "                j += 1\n",
    "\n",
    "        return (Y, Y_orig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 65,  32, 173],\n       [105,  35, 200],\n       [114,  45, 194],\n       ...,\n       [151,  12, 150],\n       [170,  53, 169],\n       [181,  95, 182]], dtype=uint8)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = Sampler()\n",
    "sam.add_path('dinner.jpg')\n",
    "sam.add_filter('noise', std = 1000)\n",
    "sam.patch_shape = np.array([1000,1000,3])\n",
    "(Y, Y_orig) = sam.sample(N=3)\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#cv2.imshow('test', Y[:,0].reshape(sam.patch_shape))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimization Algorithms\n",
    "\n",
    "Here I will define the Matching Pursuit (MP), Orthogonal Matching Pursuit (OMP), and k-means Singular Value Decomposition (k-SVD) algorithms. The k-SVD algorithm was first proposed for sparse dictionary learning in https://legacy.sites.fas.harvard.edu/~cs278/papers/ksvd.pdf. In the same algorithm I also use an unused atom replacement method examined in https://cs.unibuc.ro//~pirofti/papers/Irofti16_AtomReplacement.pdf.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def find_sparse_rep_MP(Y, D, L):\n",
    "    \"\"\"\n",
    "    :param Y: This is a (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is a (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional vectors. Each column vector must have already been normalized.\n",
    "    :param L: This is an integer satisfying 0 < L <= K representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Runs in O( N K L ) time.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    assert d == d1, f\"The dimensions dont add up: Y.shape = {Y.shape} and D.shape = {D.shape}\" # Make sure the dimensions match up\n",
    "\n",
    "    A = np.zeros((K, N)) # Get our Sparse Representation Matrix\n",
    "\n",
    "    for j in range(N):  # Iterate over all of the N given signal vectors Y[:,j].\n",
    "\n",
    "        alpha = np.zeros(K)  # Initialize the sparse representation vector (will be a column vector in A)\n",
    "        r_vec = Y[:, j] - np.dot(D, alpha)  # Initialize the \"residual\" vector\n",
    "\n",
    "        for i in range(L): # Repeat until we utilize L atoms, or no more are needed\n",
    "            position_coeff_error = []\n",
    "\n",
    "            for k in range(K): # Find the best atom, D[:,k]\n",
    "\n",
    "                atom = D[:, k]\n",
    "\n",
    "                # Project the residual vector r_vec down to the linear subspace defined by the atom\n",
    "                coeff = np.inner(r_vec, atom)\n",
    "                error = np.linalg.norm(r_vec - coeff * atom)\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2]) # Find the atom whose linear subspace is closest to the residual vector r_vec\n",
    "\n",
    "            if np.abs(coeff) < 1e-6: #If the coefficient is too small, we don't add it and instead end the iteration\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                alpha[position] += coeff # Update the sparse representation vector, alpha\n",
    "                r_vec -= coeff * D[:, position] # Update the residual vector, r_vec\n",
    "\n",
    "        A[:, j] = alpha # Insert the sparse representation vector alpha into the matrix A\n",
    "\n",
    "    return A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def find_sparse_rep_OMP(Y, D, L):\n",
    "    \"\"\"\n",
    "    Find the sparse representation of the given signals Y over the dictionary D using the Orthogonal Matching Pursuit\n",
    "    algorithm.\n",
    "    Runs in O( N K L^2 ) time.\n",
    "\n",
    "    :param Y: A (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: A (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param L: An integer representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "\n",
    "    # Initialize the sparse representation matrix A\n",
    "    A = np.zeros((K, N))\n",
    "\n",
    "    # Iterate over all of the N given signal vectors Y[:,j].\n",
    "    for j in range(N):\n",
    "\n",
    "        # Initialize the set of indices for the selected atoms\n",
    "        idx_set = set()\n",
    "\n",
    "        # Repeat until we utilize L atoms, or no more are needed\n",
    "        for i in range(L):\n",
    "\n",
    "            # Find the remaining unused atoms\n",
    "            remaining_atoms = set(range(K)).difference(idx_set)\n",
    "\n",
    "            # Initialize a list to store the coefficients and errors for each candidate atom\n",
    "            position_coeff_error = []\n",
    "\n",
    "            # Iterate over the remaining unused atoms and calculate the projection error for each\n",
    "            for k in remaining_atoms:\n",
    "                # Create the subspace basis from the remaining unused atoms plus the current candidate atom\n",
    "                subspace_basis = D[:, list(idx_set) + [k]]\n",
    "\n",
    "                # Solve for the coefficients of the projection\n",
    "                coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "                # Calculate the projected vector\n",
    "                projected = np.dot(subspace_basis, coeff)\n",
    "\n",
    "                # Calculate the error between the original signal and the projection\n",
    "                error = np.linalg.norm(Y[:, j] - projected)\n",
    "\n",
    "                # Store the position, coefficients, and error in the list\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            # Select the candidate atom with the minimum projection error\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2])\n",
    "\n",
    "            # Add the selected atom to the set of indices for the selected atoms\n",
    "            idx_set.add(position)\n",
    "\n",
    "        # Create the final subspace basis from the selected atoms\n",
    "        subspace_basis = D[:, list(idx_set)]\n",
    "\n",
    "        # Solve for the coefficients of the sparse representation using the selected atoms\n",
    "        coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "        # Initialize the sparse representation vector alpha\n",
    "        alpha = np.zeros(K)\n",
    "\n",
    "        # Insert the computed coefficients into the sparse representation vector alpha\n",
    "        for position, index in enumerate(idx_set):\n",
    "            alpha[index] = coeff[position]\n",
    "\n",
    "        # Insert the sparse representation vector alpha into the matrix A\n",
    "        A[:, j] = alpha\n",
    "\n",
    "        # Return the matrix of sparse representations\n",
    "    return A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def update_dictionary_kSVD(Y, D, A):\n",
    "    \"\"\"\n",
    "    Update the dictionary using the k-SVD algorithm. This\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "\n",
    "    :return: (D, A), where D is updated and optimized to the given  a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    (K1, N1) = A.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "    assert K == K1\n",
    "    assert N == N1\n",
    "\n",
    "    # Iterate over every atom in the dictionary\n",
    "    unused_atoms = []\n",
    "    for k in range(K):\n",
    "        # Find the signal vectors, Y[:,j], whose sparse representation, A[:,j], have a non-zero entry in the k^th position. That is, they use the k^th atom.\n",
    "        non_zero_indices = np.nonzero(A[k, :])[0]\n",
    "\n",
    "        if len(non_zero_indices) == 0:\n",
    "            unused_atoms.append(k)\n",
    "\n",
    "        else:\n",
    "            # Get the k^th \"error matrix\"\n",
    "            E = Y - np.dot(D, A) + np.outer(D[:, k], A[k, :])\n",
    "\n",
    "            # Restrict the matrix to only those non-zero values. The resulting matrix should be KxL\n",
    "            E = E[:, non_zero_indices]\n",
    "\n",
    "            # Do the SVD (Singular Value Decomposition) step to the KxL matrix E\n",
    "            U, S, V = np.linalg.svd(E, full_matrices=False)\n",
    "\n",
    "            #print(f'For the k={k} atom, E={E}, and non_zero_indices = {non_zero_indices}')\n",
    "\n",
    "            # Update the k^th atom, D[:, k], and the k^th coefficients in the sparse representation, A[k, :].\n",
    "            # Note: The k-SVD algorithm also converges when run in parallel, only updating the matrix D at the end. However running the algorithm in series, updating the atoms and coefficients after each step, produces more robust results and typically requires more than four times as long to converge.\n",
    "            D[:, k] = U[:, 0]\n",
    "            A[k, non_zero_indices] = S[0] * V[0, :]\n",
    "\n",
    "    # Replace the unused atoms with the worst represented sample vectors\n",
    "    E = Y - np.dot(D, A)\n",
    "    errors = []\n",
    "    for j in range(N):\n",
    "        errors.append((j, np.linalg.norm(E[:,j])))\n",
    "    errors.sort(key = lambda x: -x[1])\n",
    "\n",
    "    num_unused = len(unused_atoms)\n",
    "    for i in range(num_unused):\n",
    "        D[:, unused_atoms[i]] = Y[:, errors[i][0]]\n",
    "\n",
    "    return (D, A)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dictionary Learners\n",
    "\n",
    "This is the second class we will be defining. It will be doing the actual math part of the problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DictionaryLearner:\n",
    "\n",
    "    def __init__(self, L=5, K=100, sampler = None, algo = None, Dictionary = None):\n",
    "\n",
    "        assert L<K, f\"The total number of atoms, K={K}, must be greater than the maximum number of allowed atoms per sparse representation, L = {L}\"\n",
    "\n",
    "        self.L = L # The maximum number of atoms a sparse representation can use\n",
    "        self.K = K # The size of the dictionary\n",
    "        self.Dictionary = Dictionary # The initial guesses for the dictionary\n",
    "        self.sampler = sampler\n",
    "        self.select_algorithm(algo)\n",
    "        self.errors = []\n",
    "\n",
    "        self.update_dictionary_kSVD = update_dictionary_kSVD\n",
    "        self.update_step()\n",
    "\n",
    "    def set_sampler(self, sampler):\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def set_initial_dictionary(self, D):\n",
    "        self.Dictionary = D\n",
    "\n",
    "    def select_algorithm(self, algo):\n",
    "        if algo == 'MP':\n",
    "            self.sparse_rep = find_sparse_rep_MP\n",
    "        elif algo == 'OMP':\n",
    "            self.sparse_rep = sparse_rep = find_sparse_rep_OMP\n",
    "\n",
    "        else:\n",
    "            self.sparse_rep = None\n",
    "\n",
    "    def update_step(self, inner_loop = 1, use_orig = False):\n",
    "        def update_dictionary(Y, Y_orig, D, A):\n",
    "            for i in range(inner_loop):\n",
    "                if use_orig:\n",
    "                    (D, A) = self.update_dictionary_kSVD(Y_orig, D, A)\n",
    "                else:\n",
    "                    (D,A) = self.update_dictionary_kSVD(Y, D, A)\n",
    "            return (D,A)\n",
    "        self.update_dictionary = update_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def sparse_dictionary_learning(self, iters=10, output = True):\n",
    "    \"\"\"\n",
    "    This algorithm finds a (d x K) matrix D (the dictionary) and a (K x N) matrix A (the sparse representation) which minimise the L2 distance between Y and D A, ie, minimise ||Y - D A ||, subject to the constraint that each column of A has at most L non-zero elements.\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param K: An integer representing the size of the dictionary.\n",
    "    :param L: An integer representing the maximum number of \"atoms\", D[:, k], in the dictionary that each sparse representation vector, A[:, i], can use.\n",
    "\n",
    "    Note: This algorithm is written under the assumption that: 0 < L < d < K < N\n",
    "\n",
    "    :param D_initial: This is the initial guess for the (d x N) matrix D. If not None, the columns of this matrix must be unit length.\n",
    "    :param algo: This is a string defining the sparse representation algorithm. Either algo = 'OMP' for Orhtogonal Matching Pursuit, or algo = 'MP' for Matching Pursuit.\n",
    "    :param iters: The number of iterations this will run for\n",
    "    :param with_errors: A boolean which determines if the output includes the list of the error values at each step of the iteration.\n",
    "    :param samples: This tells us the number of random samples to take from the training data Y at each step\n",
    "\n",
    "    :return: (D, A, errors)\n",
    "        D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors.\n",
    "        A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "        errors: This is an optional output. It is the list of the error values at each step of the iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we have the proper stuff defined\n",
    "    assert self.sparse_rep != None\n",
    "\n",
    "    # Get the internal variables for ease\n",
    "    K = self.K\n",
    "    L = self.L\n",
    "    sampler = self.sampler\n",
    "    D = self.Dictionary\n",
    "    sparse_rep = self.sparse_rep\n",
    "    update_dictionary = self.update_dictionary\n",
    "\n",
    "    # Get Initial Dictionary if there is none\n",
    "    if D == None:\n",
    "        (Y, _) = sampler.sample()\n",
    "        N = len(Y[0, :])\n",
    "        D = Y[:, random.sample(range(N), k=K)]\n",
    "        D = D / np.linalg.norm(D, axis=0)\n",
    "\n",
    "    for step in tqdm(range(iters)):\n",
    "\n",
    "        # Get the batch of random samples\n",
    "        (Y, Y_orig) = sampler.sample()\n",
    "\n",
    "        # Find the Sparse Representations\n",
    "        A = sparse_rep(Y, D, L)\n",
    "\n",
    "        # Record the error\n",
    "        error = np.linalg.norm(Y - np.dot(D, A))\n",
    "        self.errors.append(error)\n",
    "\n",
    "        # Update the Dictionary\n",
    "        (D, A) = update_dictionary(Y, Y_orig, D, A)\n",
    "\n",
    "    # Record the error one last time\n",
    "    A = sparse_rep(Y, D, L)\n",
    "    error = np.linalg.norm(Y - np.dot(D, A))\n",
    "    self.errors.append(error)\n",
    "\n",
    "    # Update Dictionary\n",
    "    self.Dictionary = D\n",
    "\n",
    "    if output:\n",
    "        return D\n",
    "\n",
    "DictionaryLearner.sparse_dictionary_learning = sparse_dictionary_learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f9a1b09a6cf48cfac8535a4179eef70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sam = Sampler(paths = ['dinner.jpg'])\n",
    "learner = DictionaryLearner(L=5, K=200, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 1, output = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def image_reconstruction(self, path):\n",
    "\n",
    "    # Get internal stuff for ease of use\n",
    "    D = self.Dictionary\n",
    "    patch_shape = self.sampler.patch_shape\n",
    "    patch_size = patch_shape[0]\n",
    "    L = self.L\n",
    "\n",
    "    img = load_image(path)\n",
    "    large_shape = img.shape\n",
    "    num_rows, num_cols = large_shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    pbar = tqdm(total=num_patches_rows*num_patches_cols)\n",
    "\n",
    "    # Loop over all patches in the image\n",
    "    for i in range(num_patches_rows):\n",
    "        for j in range(num_patches_cols):\n",
    "            # Extract the patch from the image\n",
    "            patch = img[i:i+patch_size, j:j+patch_size, ...]\n",
    "\n",
    "            # Compute the sparse coding of the patch\n",
    "            sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "            recon_patch = np.dot(D, sparse_patch_code)\n",
    "            recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "            # Add the reconstructed patch to the reconstructed image\n",
    "            recon_img[i:i+patch_size, j:j+patch_size, ...] += recon_patch\n",
    "            count[i:i+patch_size, j:j+patch_size, ...] += 1\n",
    "\n",
    "            # Increment the counter variable and update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    pbar.close()\n",
    "\n",
    "    # Average the pixel values at each pixel to get the final reconstructed image\n",
    "    recon_img /= count\n",
    "\n",
    "    # Convert the reconstructed image to uint8\n",
    "    recon_img = np.clip(recon_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return recon_img\n",
    "\n",
    "DictionaryLearner.image_reconstruction = image_reconstruction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image Size\n",
    "\n",
    "After a few tests, it became clear that my computer (and patience) will not handle reconstructing large photos. So I will be compressing the photos down to 200x150 pixels. For now I will also be considering only black and white photos. Below we see the Original photo, along side the lower resolution version that I will be feeding into my algorithms\n",
    "\n",
    "| Original (High Resolution)                                       | Compressed (Low Resolution)                                                 |\n",
    "|------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| <img alt=\"Caption 1\" height=\"300\" src=\"dinner.jpg\" width=\"400\"/> | <img alt=\"Caption 2\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('dinner.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Resize the image to 400x300 pixels\n",
    "img_resized = cv2.resize(img, (200, 150), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Convert the resized image to grayscale\n",
    "img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "print(img_gray.shape)\n",
    "\n",
    "# Save the grayscale image as 'small_gray_dinner.png'\n",
    "cv2.imwrite('small_gray_dinner.png', img_gray )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#img = load_image('small_gray_dinner.png')\n",
    "#print(img.shape)\n",
    "#cv2.imshow('test',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learner.errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.png'], patch_shape=np.array([8,8]), num_samples=500 )\n",
    "learner = DictionaryLearner(L=20, K=100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 10, output = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = 'small_gray_dinner.png'\n",
    "reconI10L20_img = learner.image_reconstruction(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv2.imwrite('reconI10L20_small_gray_dinner.png', reconI10L20_img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('Reconstruction0', recon0_img)\n",
    "cv2.moveWindow(\"Reconstruction0\", 0, 0)\n",
    "\n",
    "cv2.imshow('Reconstruction1', recon_img)\n",
    "cv2.moveWindow(\"Reconstruction1\", recon0_img.shape[1], 0)\n",
    "\n",
    "cv2.imshow('Reconstruction10K500', recon10K500_img)\n",
    "cv2.moveWindow(\"Reconstruction10K500\", recon_img.shape[1] + recon0_img.shape[1], 0)\n",
    "\n",
    "cv2.imshow('ReconstructionI10L20', reconI10L20_img)\n",
    "cv2.moveWindow(\"ReconstructionI10L20\", recon_img.shape[1] + recon0_img.shape[1] + recon10K500_img.shape[1], 0)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.moveWindow(\"Original\", recon_img.shape[1] + recon0_img.shape[1] + recon10K500_img.shape[1] + reconI10L20_img.shape[1], 0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_orig = load_image('small_gray_dinner.png')\n",
    "img_recon1 = load_image('recon_small_gray_dinner.png')\n",
    "img_recon10 = load_image('recon10_small_gray_dinner.png')\n",
    "recon10K500_img = load_image('recon10K500_small_gray_dinner.png')\n",
    "recon0_img = load_image('recon0_small_gray_dinner.png')\n",
    "\n",
    "num_pixels = np.array(img_orig.shape).prod()\n",
    "\n",
    "error0 = np.linalg.norm(img_orig-recon0_img)/np.sqrt(num_pixels)\n",
    "error1 = np.linalg.norm(img_orig-img_recon1)/np.sqrt(num_pixels)\n",
    "error10 = np.linalg.norm(img_orig - img_recon10)/np.sqrt(num_pixels)\n",
    "error10K500 = np.linalg.norm(img_orig - recon10K500_img)/np.sqrt(num_pixels)\n",
    "errorI10L20 = np.linalg.norm(img_orig - reconI10L20_img)/np.sqrt(num_pixels)\n",
    "\n",
    "print(f'Error after 0 iterations: {error0}')\n",
    "print(f'Error after 1 iterations: {error1}')\n",
    "print(f'Error after 10 iterations: {error10}')\n",
    "print(f'Error after 10 iterations (with batch size of N=500): {error10K500}')\n",
    "print(f'Error after 10 iterations (with batch size of N=500, and L=20): {errorI10L20}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#D10 = learner.Dictionary\n",
    "#D10K500 = learner.Dictionary\n",
    "#D0 = learner.Dictionary\n",
    "#DI10L20 = learner.Dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison\n",
    "\n",
    "Here are the results of a few tests. Note that these tests are purely to get an idea of what the algorithms are capable of. A full battery of tests will be preformed in another notebook.\n",
    "\n",
    "ALl tests are run by compressing and reconstructing a single image. The algorithm is trained and tested on the same image.\n",
    "\n",
    "I = number of iterations of the dictionary learning algorithm (k-SVD)\n",
    "K = number of atoms\n",
    "L = max number of atoms allowed in a sparse representation\n",
    "N = number of random samples provided (batch size) at each step\n",
    "\n",
    "### Dictionary Learning Iterations\n",
    "How many iterations (I = num_iters) of the dictionary learning (k-SVD) algorithm do we need to run? Note that at I=0 our atoms are initialized as random patches of our image.\n",
    "\n",
    "| I = 0 | I = 1 | I = 10 | Original |\n",
    "|-------|-------|--------|----------|\n",
    "| <img alt=\"Recon 0\" height=\"300\" src=\"recon0_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Recon 1\" height=\"300\" src=\"recon_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Recon 10\" height=\"300\" src=\"recon10_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Original\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> |\n",
    "\n",
    "Notice how there isn't much of a difference.\n",
    "\n",
    "### Batch Size\n",
    "How many samples should I provide? Both experiments were preformed with I=10\n",
    "\n",
    " N=100  | N=500                                          | Original |\n",
    "-------|------------------------------------------------|----------|\n",
    "| <img alt=\"Recon 1\" height=\"300\" src=\"recon10_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Recon 10\" height=\"300\" src=\"recon10K500_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Original\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> |\n",
    "\n",
    "Again, not much of a change.\n",
    "\n",
    "### Atoms in the Sparse Representation\n",
    "How many atoms should I use in the sparse representation?\n",
    "\n",
    " L=5 | L=20                                                                                   | Original |\n",
    "-------|----------------------------------------------------------------------------------------|----------|\n",
    "| <img alt=\"Recon 1\" height=\"300\" src=\"recon10K500_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Recon 10\" height=\"300\" src=\"reconI10L20_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Original\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> |\n",
    "\n",
    "We finally have a dramatic improvement. It seems that of all the parameters, L is by far the most important."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Partial Image Reconstruction (SPIR)\n",
    "\n",
    "During the previous experiments I learned that image reconstruction is extremely slow since I need to do sparse coding for every 8x8 patch. This led to the idea of using a stochastic method to only randomly select patches. Surely with enough patches I should be able to reconstruct most of the image. And more importantly, I will be able to get an accurate estimate of the error without reconstructing the whole thing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SPIR_plot(self, path):\n",
    "\n",
    "    mincounts = [1,2,3,4,5,10,20,40,60]\n",
    "    df = pd.DataFrame(columns=mincounts)\n",
    "\n",
    "    # Get internal stuff for ease of use\n",
    "    D = self.Dictionary\n",
    "    patch_shape = self.sampler.patch_shape\n",
    "    patch_size = patch_shape[0]\n",
    "    L = self.L\n",
    "\n",
    "    img = load_image(path)\n",
    "    large_shape = img.shape\n",
    "    num_rows, num_cols = large_shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "    num_patches = num_patches_cols*num_patches_rows\n",
    "\n",
    "    #print(f'The image shape is {img.shape} with ')\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total = int(1.5*num_patches)\n",
    "    pbar = tqdm(total=total)\n",
    "\n",
    "    for i in range(total):\n",
    "\n",
    "        index = random.randint(0,num_patches-1)\n",
    "        row_idx, col_idx  = (index // num_patches_cols, index % num_patches_cols)\n",
    "\n",
    "        # Extract the patch from the image\n",
    "        patch = img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...]\n",
    "\n",
    "        # Compute the sparse coding of the patch\n",
    "        #print(f'The patch shape is patch.shape = {patch.shape}')\n",
    "        #print(f'The patch is patch = {patch}')\n",
    "        #print(f'It ought to be [{row_idx}:{row_idx+patch_size}, {col_idx}:{col_idx+patch_size}]')\n",
    "        sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "        recon_patch = np.dot(D, sparse_patch_code)\n",
    "        recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "        # Add the reconstructed patch to the reconstructed image\n",
    "        recon_img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += recon_patch\n",
    "        count[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += 1\n",
    "\n",
    "        # Increment the counter variable and update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        if i%100 == 0:\n",
    "\n",
    "            temp_recon = recon_img.copy().flatten()\n",
    "            temp_count = count.copy().flatten()\n",
    "            temp_img = img.copy().flatten()\n",
    "\n",
    "            for m in mincounts:\n",
    "                temp_indices = np.where(temp_count>m)[0]\n",
    "                M = len(temp_indices)\n",
    "                error = np.linalg.norm(temp_img[temp_indices] -  (temp_recon[temp_indices]/temp_count[temp_indices]))/np.sqrt(M)\n",
    "\n",
    "                df.loc[i, m] = error\n",
    "\n",
    "    return df\n",
    "\n",
    "DictionaryLearner.SPIR_plot = SPIR_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.png'], patch_shape=np.array([8,8]), num_samples=300 )\n",
    "learner = DictionaryLearner(L=5, K=100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 10, output = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = learner.SPIR_plot('small_gray_dinner.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define total as the maximum value of the index\n",
    "total = (200-8)*(150-8)\n",
    "\n",
    "# set the x-axis values as a percentage\n",
    "x_values = df.index.values / total * 100\n",
    "\n",
    "# increase width of plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plot each column as a line plot with labels\n",
    "for column in [1, 3, 5, 10]:\n",
    "    y_values = df[column].values\n",
    "    label = \"min_count = \" + str(column)\n",
    "    plt.plot(x_values, y_values, label=label)\n",
    "\n",
    "# set y-axis limits to between 4 and 10\n",
    "plt.ylim(4, 10)\n",
    "\n",
    "# add a legend and axis labels\n",
    "plt.legend()\n",
    "plt.xlabel('Percentage of total')\n",
    "plt.ylabel('Error Estimate')\n",
    "\n",
    "# set the title of the plot\n",
    "plt.title(\"How quickly can we get a good estimate of the error?\")\n",
    "\n",
    "plt.savefig('SPIR_graph.jpg')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "\n",
    "We conclude that using only about 20% of the patches with a min_count = 1 should be sufficient to get an accurate estimate of the error."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SPIR(self, path, percent = .2, min_count = 1):\n",
    "\n",
    "    # Get internal stuff for ease of use\n",
    "    D = self.Dictionary\n",
    "    patch_shape = self.sampler.patch_shape\n",
    "    patch_size = patch_shape[0]\n",
    "    L = self.L\n",
    "\n",
    "    img = load_image(path)\n",
    "    large_shape = img.shape\n",
    "    num_rows, num_cols = large_shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "    num_patches = num_patches_cols*num_patches_rows\n",
    "\n",
    "    #print(f'The image shape is {img.shape} with ')\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total = int(percent*num_patches)\n",
    "    pbar = tqdm(total=total)\n",
    "\n",
    "    for i in range(total):\n",
    "\n",
    "        index = random.randint(0,num_patches-1)\n",
    "        row_idx, col_idx  = (index // num_patches_cols, index % num_patches_cols)\n",
    "\n",
    "        # Extract the patch from the image\n",
    "        patch = img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...]\n",
    "\n",
    "        # Compute the sparse coding of the patch\n",
    "        sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "        recon_patch = np.dot(D, sparse_patch_code)\n",
    "        recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "        # Add the reconstructed patch to the reconstructed image\n",
    "        recon_img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += recon_patch\n",
    "        count[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += 1\n",
    "\n",
    "        # Increment the counter variable and update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "    temp_recon = recon_img.copy().flatten()\n",
    "    temp_count = count.copy().flatten()\n",
    "    temp_img = img.copy().flatten()\n",
    "    temp_indices = np.where(temp_count>min_count)[0]\n",
    "    M = len(temp_indices)\n",
    "    error = np.linalg.norm(temp_img[temp_indices] -  (temp_recon[temp_indices]/temp_count[temp_indices]))/np.sqrt(M)\n",
    "\n",
    "    recon_img = recon_img // count\n",
    "    recon_img = np.clip(recon_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return (recon_img, error)\n",
    "\n",
    "DictionaryLearner.SPIR = SPIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.png'], patch_shape=np.array([8,8]), num_samples=300 )\n",
    "learner = DictionaryLearner(L=5, K=100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 10, output = False)\n",
    "recon, error = learner.SPIR('small_gray_dinner.png')\n",
    "print(f'The estimated error = {error}')\n",
    "\n",
    "cv2.imwrite('precon10_small_gray_dinner.png', recon)\n",
    "#cv2.imshow('SPIR', recon)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison\n",
    "\n",
    "Below we compare the full reconstruction to the partial reconstruction of this image. The parameters were otherwise the same (N=300, I=10, K=100, L=5)\n",
    "\n",
    " Full Reconstruction  | Partial Reconstruction                                                              |\n",
    "-------|-------------------------------------------------------------------------------------|\n",
    "| <img alt=\"Recon 1\" height=\"300\" src=\"recon10_small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Recon 10\" height=\"300\" src=\"precon10_small_gray_dinner.png\" width=\"400\"/> |\n",
    "\n",
    "\n",
    "Note that when we do our error estimation, we ignore the missing pixels.\n",
    "\n",
    "Keep in mind the later method is takes 20% the runtime and only slightly overestimates the error.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recon"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img alt=\"text 1\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/>\n",
    "<img alt=\"text 2\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "| Title 1 | Title 2 |\n",
    "|---------|---------|\n",
    "| <img alt=\"Caption 1\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> | <img alt=\"Caption 2\" height=\"300\" src=\"small_gray_dinner.png\" width=\"400\"/> |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example input arrays\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 0, 1])\n",
    "\n",
    "# Example 1: Convert output to float using astype()\n",
    "c = np.true_divide(a, b).astype(float)\n",
    "print(c)  # output: [0.5 inf 3.0]\n",
    "\n",
    "# Example 2: Use floor division operator //\n",
    "d = a // b\n",
    "print(d)  # output: [0 -9223372036854775808 3]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array([29])//np.array([0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.png'], patch_shape=np.array([8,8]), num_samples=300 )\n",
    "learner = DictionaryLearner(L=20, K=100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 10, output = False)\n",
    "error = learner.SPIR('small_gray_dinner.png')\n",
    "print(f'The estimated error = {error}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "specific_indicies = np.extract(a > 0, a)\n",
    "b = a.copy()\n",
    "b.flatten()[specific_indicies]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def SPIRplus_plot(self, path):\n",
    "\n",
    "    mincounts = [1,2,4,8,16,32]\n",
    "    df = pd.DataFrame(columns=mincounts)\n",
    "\n",
    "    # Get internal stuff for ease of use\n",
    "    D = self.Dictionary\n",
    "    patch_shape = self.sampler.patch_shape\n",
    "    patch_size = patch_shape[0]\n",
    "    L = self.L\n",
    "\n",
    "    img = load_image(path)\n",
    "    large_shape = img.shape\n",
    "    num_rows, num_cols = large_shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "    num_patches = num_patches_cols*num_patches_rows\n",
    "\n",
    "    #print(f'The image shape is {img.shape} with ')\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total = int(.2*num_patches + (num_patches_rows//patch_size)*(num_patches_cols // patch_size))\n",
    "    pbar = tqdm(total=total)\n",
    "\n",
    "    # Get patches that barely cover the image\n",
    "    for row_idx in range(num_patches_rows//patch_size):\n",
    "        for col_idx in range(num_patches_cols // patch_size):\n",
    "\n",
    "            # Extract the patch from the image\n",
    "            patch = img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...]\n",
    "\n",
    "            # Compute the sparse coding of the patch\n",
    "            sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "            recon_patch = np.dot(D, sparse_patch_code)\n",
    "            recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "            # Add the reconstructed patch to the reconstructed image\n",
    "            recon_img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += recon_patch\n",
    "            count[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += 1\n",
    "\n",
    "            # Increment the counter variable and update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    predone = (num_patches_rows//patch_size)*(num_patches_cols // patch_size)\n",
    "\n",
    "    for i in range(int(.2*num_patches)):\n",
    "\n",
    "        index = random.randint(0,num_patches-1)\n",
    "        row_idx, col_idx  = (index // num_patches_cols, index % num_patches_cols)\n",
    "\n",
    "        # Extract the patch from the image\n",
    "        patch = img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...]\n",
    "\n",
    "        # Compute the sparse coding of the patch\n",
    "        sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "        recon_patch = np.dot(D, sparse_patch_code)\n",
    "        recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "        # Add the reconstructed patch to the reconstructed image\n",
    "        recon_img[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += recon_patch\n",
    "        count[row_idx:row_idx+patch_size, col_idx:col_idx+patch_size, ...] += 1\n",
    "\n",
    "        # Increment the counter variable and update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        if i%100 == 0:\n",
    "\n",
    "            temp_recon = recon_img.copy().flatten()\n",
    "            temp_count = count.copy().flatten()\n",
    "            temp_img = img.copy().flatten()\n",
    "\n",
    "            for m in mincounts:\n",
    "                temp_indices = np.where(temp_count>m)[0]\n",
    "                M = len(temp_indices)\n",
    "                error = np.linalg.norm(temp_img[temp_indices] -  (temp_recon[temp_indices]/temp_count[temp_indices]))/np.sqrt(M)\n",
    "\n",
    "                df.loc[i + predone, m] = error\n",
    "\n",
    "    return df\n",
    "\n",
    "DictionaryLearner.SPIRplus_plot = SPIRplus_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.png'], patch_shape=np.array([8,8]), num_samples=300 )\n",
    "learner = DictionaryLearner(L=5, K=100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 10, output = False)\n",
    "df2 = learner.SPIRplus_plot('small_gray_dinner.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define total as the maximum value of the index\n",
    "total = (200-8)*(150-8)\n",
    "\n",
    "# set the x-axis values as a percentage\n",
    "x_values = df2.index.values / total * 100\n",
    "\n",
    "# increase width of plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plot each column as a line plot with labels\n",
    "for column in df2.columns:\n",
    "    y_values = df2[column].values\n",
    "    label = \"min_count = \" + str(column)\n",
    "    plt.plot(x_values, y_values, label=label)\n",
    "\n",
    "# set y-axis limits to between 4 and 10\n",
    "plt.ylim(4, 10)\n",
    "\n",
    "# add a legend and axis labels\n",
    "plt.legend()\n",
    "plt.xlabel('Percentage of total')\n",
    "plt.ylabel('Error Estimate')\n",
    "\n",
    "# set the title of the plot\n",
    "plt.title(\"How quickly can we get a good estimate of the error?\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reconstruct_image(D, img, patch_size, alpha):\n",
    "    # Compute the number of patches in the image\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Loop over all patches in the image\n",
    "    for i in tqdm(range(num_patches_rows)):\n",
    "        for j in range(num_patches_cols):\n",
    "            # Extract the patch from the image\n",
    "            patch = img[i:i+patch_size, j:j+patch_size, :]\n",
    "\n",
    "            # Compute the sparse coding of the patch\n",
    "            code = find_sparse_rep_OMP(Y, D, L)\n",
    "            sparse_code(D, patch, alpha)\n",
    "\n",
    "        # Reconstruct the patch using the dictionary\n",
    "        recon_patch = np.dot(D, code)\n",
    "        recon_patch = np.reshape(recon_patch, (patch_size, patch_size, 3))\n",
    "\n",
    "        # Add the reconstructed patch to the reconstructed image\n",
    "        recon_img[i:i+patch_size, j:j+patch_size, :] += recon_patch\n",
    "        count[i:i+patch_size, j:j+patch_size, :] += 1\n",
    "\n",
    "# Average the pixel values at each pixel to get the final reconstructed image\n",
    "recon_img /= count\n",
    "\n",
    "# Convert the reconstructed image to uint8\n",
    "recon_img = np.clip(recon_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "return recon_img\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([1,2,3]).prod()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.normal(0, 0.1, np.array([8,8]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
