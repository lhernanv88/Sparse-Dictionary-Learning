{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def get_ith_patch(large_shape, patch_shape, i):\n",
    "    # How many patches can we fit in this large array?\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "\n",
    "    # What are the coordinates of the starting pixel of the ith patch?\n",
    "    patch_index = np.unravel_index(i, patch_index_shape)\n",
    "\n",
    "    # Get the indices for the pixels in the ith patch\n",
    "    patch_indices = tuple(slice(start, start + size) for start, size in zip(patch_index, patch_shape))\n",
    "\n",
    "    return patch_indices\n",
    "\n",
    "def get_num_patches(large_shape, patch_shape):\n",
    "    patch_index_shape = np.array(large_shape) - np.array(patch_shape) + 1\n",
    "    return patch_index_shape.prod()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "def laod_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    if (img[:,:,0] == img[:,:,1]).all():\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, paths = [], num_samples = 300, patch_shape = np.array([8,8,3])):\n",
    "        #self.seed = 1 # A random seed which will be updated after every use. It is there to ensure reproducibility\n",
    "        self.paths = paths # A list of the paths where original images/signals are stored\n",
    "        self.add_filter(None)\n",
    "        self.num_samples = num_samples\n",
    "        self.patch_shape = patch_shape\n",
    "\n",
    "    def set_patch_shape(self, patch_shape):\n",
    "        self.patch_shape = patch_shape\n",
    "\n",
    "    def set_num_samples(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def add_path(self, path):\n",
    "        self.paths.append(path)\n",
    "\n",
    "    def set_paths(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def add_filter(self, filter, std = 10):\n",
    "\n",
    "        if filter == None:\n",
    "            foo = lambda x: x\n",
    "            self.filter = foo\n",
    "\n",
    "        elif filter == 'noise':\n",
    "\n",
    "            def filter(self, sample):\n",
    "\n",
    "                noise = np.zeros_like(sample)\n",
    "                cv2.randn(noise, 0, std)\n",
    "                sample = np.clip(sample + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "                return sample\n",
    "            self.filter = filter\n",
    "\n",
    "    def sample(self, N = None):\n",
    "        \"\"\"\n",
    "        A function which returns N samples. It returns a pair of matrices (Y_corrupted, Y_original).\n",
    "\n",
    "        :param N:\n",
    "        :param two_copies:\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        def get_sample(img1, img2):\n",
    "            \"\"\"\n",
    "            Helper function to get a single patch sample from an image.\n",
    "            Args:\n",
    "                img: np.array, representing an image\n",
    "                add_noise: bool, whether to add Gaussian noise to the patch\n",
    "            Returns:\n",
    "                sample: np.array, of shape (d,), representing the sampled patch\n",
    "            \"\"\"\n",
    "\n",
    "            # Get a random patch from the image\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "\n",
    "            return (img1[patch].flatten(), img2[patch].flatten())\n",
    "\n",
    "\n",
    "        # Get the number of samples\n",
    "        if N == None:\n",
    "            N = self.num_samples\n",
    "\n",
    "        # Get the product of the patch dimensions\n",
    "        d = self.patch_shape.prod()\n",
    "\n",
    "        # Initialize an array to hold the sampled patches\n",
    "        Y = np.zeros([d, N], dtype=np.uint8)\n",
    "        Y_orig = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "        # Divide the number of samples requested evenly amongst each original full image\n",
    "        j = 0\n",
    "        r = N % len(self.paths)\n",
    "\n",
    "        for i, path in enumerate(self.paths):\n",
    "\n",
    "            # Read in the image, apply the filter, and if nessisary preserve the original copy\n",
    "            img2 = laod_image(path)\n",
    "            img1 = self.filter(img2)\n",
    "\n",
    "            # Get the shape of the image\n",
    "            large_shape = img1.shape\n",
    "\n",
    "            # Get the number of patches that can be extracted from the image\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "\n",
    "            # Sample patches from the image\n",
    "            for _ in range(N // len(self.paths)):\n",
    "                (corrupted_sample, original_sample) = get_sample(img1, img2)\n",
    "                Y[:, j] = corrupted_sample\n",
    "                Y_orig[:, j] = original_sample\n",
    "                j += 1\n",
    "\n",
    "            # If there are any remaining samples, sample them from the current image\n",
    "            if i < r:\n",
    "                (corrupted_sample, original_sample) = get_sample(img1, img2)\n",
    "                Y[:, j] = corrupted_sample\n",
    "                Y_orig[:, j] = original_sample\n",
    "                j += 1\n",
    "\n",
    "        return (Y, Y_orig)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, None)"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "\n",
    "#def signal_to_vec(self, signal):\n",
    "\n",
    "#def vec_to_signal(self, vec):\n",
    "\n",
    "def sample(self, N):\n",
    "\n",
    "    # Divide the number of samples requested evenly amongst each original full image\n",
    "    j = 0\n",
    "    r = N % len(self.paths)\n",
    "    d = self.patch_shape.prod()\n",
    "    Y = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "    for i, path in enumerate(self.paths):\n",
    "        img = laod_image(path)\n",
    "        large_shape = img.shape\n",
    "\n",
    "        for _ in range(N // len(self.paths)):\n",
    "\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "            Y[:, j] = img[patch].flatten().ravel()\n",
    "            j+=1\n",
    "        if i<r:\n",
    "            num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "            patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "            Y[:, j] = img[patch]\n",
    "            j+=1\n",
    "\n",
    "    return Y\n",
    "\n",
    "def sample_noise(self, N, add_noise=False, noise_std=10):\n",
    "    \"\"\"\n",
    "    Randomly sample patches from images in self.paths, with the option to add Gaussian noise.\n",
    "    Args:\n",
    "        N: int, number of patches to sample\n",
    "        add_noise: bool, whether to add Gaussian noise to the patches\n",
    "        noise_std: float, standard deviation of the Gaussian noise\n",
    "    Returns:\n",
    "        Y: np.array, of shape (d, N), where d is the product of the patch dimensions, containing the sampled patches\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the product of the patch dimensions\n",
    "    d = self.patch_shape.prod()\n",
    "\n",
    "    # Initialize an array to hold the sampled patches\n",
    "    Y = np.zeros([d, N], dtype=np.uint8)\n",
    "\n",
    "    def get_sample(img, add_noise):\n",
    "        \"\"\"\n",
    "        Helper function to get a single patch sample from an image.\n",
    "        Args:\n",
    "            img: np.array, representing an image\n",
    "            add_noise: bool, whether to add Gaussian noise to the patch\n",
    "        Returns:\n",
    "            sample: np.array, of shape (d,), representing the sampled patch\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a random patch from the image\n",
    "        patch = get_ith_patch(large_shape, self.patch_shape, random.randint(0, num_patches))\n",
    "        sample = img[patch].flatten()\n",
    "\n",
    "        # Add Gaussian noise to the patch, if specified\n",
    "        if add_noise:\n",
    "            noise = np.zeros_like(sample)\n",
    "            cv2.randn(noise, 0, noise_std)\n",
    "            sample = np.clip(sample + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    # Divide the number of samples requested evenly amongst each original full image\n",
    "    j = 0\n",
    "    r = N % len(self.paths)\n",
    "\n",
    "    for i, path in enumerate(self.paths):\n",
    "        # Read in the image and get its shape\n",
    "        img = cv2.imread(path)\n",
    "        large_shape = img.shape\n",
    "\n",
    "        # Get the number of patches that can be extracted from the image\n",
    "        num_patches = get_num_patches(large_shape, self.patch_shape)\n",
    "\n",
    "        # Sample patches from the image\n",
    "        for _ in range(N // len(self.paths)):\n",
    "            sample = get_sample(img, add_noise)\n",
    "            Y[:, j] = sample\n",
    "            j += 1\n",
    "\n",
    "        # If there are any remaining samples, sample them from the current image\n",
    "        if i < r:\n",
    "            sample = get_sample(img, add_noise)\n",
    "            Y[:, j] = sample\n",
    "            j += 1\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "Sampler.sample = sample\n",
    "Sampler.sample_noise = sample_noise\n",
    "\n",
    "\n",
    "#def add_noise(self, signal):\n",
    "\n",
    "#def drop_pixels(self, signal):\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample() missing 1 required positional argument: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\4261881808.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0msam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpatch_shape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample_noise\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0madd_noise\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise_std\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msam\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;31m#cv2.imshow('test', Y[:,0].reshape(sam.patch_shape))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m#cv2.waitKey(0)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: sample() missing 1 required positional argument: 'N'"
     ]
    }
   ],
   "source": [
    "sam = Sampler()\n",
    "sam.add_path('dinner.jpg')\n",
    "sam.patch_shape = np.array([1000,1000,3])\n",
    "Y = sam.sample_noise(3, add_noise=True, noise_std=1000)\n",
    "Y = sam.sample()\n",
    "#cv2.imshow('test', Y[:,0].reshape(sam.patch_shape))\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[129,  44],\n       [147,  47],\n       [164,  55],\n       [128,  46],\n       [146,  49],\n       [163,  57],\n       [127,  44],\n       [145,  46],\n       [162,  54],\n       [127,  50],\n       [145,  52],\n       [162,  60],\n       [127,  55],\n       [145,  57],\n       [162,  65],\n       [127,  58],\n       [145,  60],\n       [162,  68],\n       [130,  58],\n       [146,  60],\n       [163,  68],\n       [131,  56],\n       [147,  58],\n       [164,  66],\n       [125,  41],\n       [143,  44],\n       [160,  52],\n       [126,  46],\n       [144,  49],\n       [161,  57],\n       [127,  53],\n       [145,  55],\n       [162,  63],\n       [129,  50],\n       [147,  52],\n       [164,  60],\n       [129,  51],\n       [147,  53],\n       [164,  61],\n       [127,  57],\n       [145,  59],\n       [162,  67],\n       [128,  60],\n       [144,  62],\n       [161,  70],\n       [127,  55],\n       [143,  57],\n       [160,  65],\n       [125,  41],\n       [142,  44],\n       [161,  52],\n       [124,  46],\n       [141,  49],\n       [160,  57],\n       [124,  46],\n       [141,  48],\n       [160,  56],\n       [123,  53],\n       [140,  55],\n       [159,  63],\n       [123,  58],\n       [140,  60],\n       [159,  68],\n       [124,  57],\n       [141,  59],\n       [160,  67],\n       [124,  53],\n       [141,  55],\n       [160,  63],\n       [125,  50],\n       [142,  52],\n       [161,  60],\n       [117,  39],\n       [134,  42],\n       [155,  50],\n       [118,  47],\n       [135,  50],\n       [154,  58],\n       [120,  48],\n       [137,  50],\n       [158,  58],\n       [121,  53],\n       [138,  55],\n       [157,  63],\n       [121,  57],\n       [138,  59],\n       [159,  67],\n       [120,  53],\n       [137,  55],\n       [156,  63],\n       [118,  48],\n       [135,  50],\n       [156,  58],\n       [117,  47],\n       [134,  49],\n       [153,  57],\n       [114,  39],\n       [130,  42],\n       [153,  50],\n       [115,  41],\n       [132,  44],\n       [153,  52],\n       [115,  49],\n       [131,  51],\n       [154,  59],\n       [114,  50],\n       [131,  52],\n       [152,  60],\n       [114,  50],\n       [130,  52],\n       [153,  60],\n       [114,  49],\n       [131,  51],\n       [152,  59],\n       [114,  48],\n       [130,  50],\n       [153,  58],\n       [113,  47],\n       [130,  49],\n       [151,  57],\n       [109,  42],\n       [125,  45],\n       [148,  53],\n       [110,  48],\n       [126,  51],\n       [149,  59],\n       [109,  49],\n       [125,  51],\n       [148,  59],\n       [108,  47],\n       [124,  49],\n       [147,  57],\n       [108,  44],\n       [124,  46],\n       [147,  54],\n       [108,  45],\n       [124,  47],\n       [147,  55],\n       [107,  49],\n       [123,  51],\n       [146,  59],\n       [106,  48],\n       [122,  50],\n       [145,  58],\n       [102,  46],\n       [116,  49],\n       [139,  57],\n       [103,  46],\n       [117,  49],\n       [140,  57],\n       [102,  47],\n       [116,  49],\n       [139,  57],\n       [101,  46],\n       [115,  48],\n       [138,  56],\n       [100,  43],\n       [114,  45],\n       [137,  53],\n       [100,  43],\n       [114,  45],\n       [137,  53],\n       [100,  47],\n       [114,  49],\n       [137,  57],\n       [ 99,  47],\n       [113,  49],\n       [136,  57],\n       [ 94,  46],\n       [106,  49],\n       [130,  57],\n       [ 95,  48],\n       [107,  51],\n       [131,  59],\n       [ 95,  44],\n       [107,  46],\n       [131,  54],\n       [ 94,  47],\n       [106,  49],\n       [130,  57],\n       [ 93,  47],\n       [105,  49],\n       [129,  57],\n       [ 94,  43],\n       [106,  45],\n       [130,  53],\n       [ 95,  43],\n       [105,  45],\n       [129,  53],\n       [ 95,  44],\n       [105,  46],\n       [129,  54]], dtype=uint8)"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = Sampler(paths = ['dinner.jpg'])\n",
    "sam.sample(N=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_sparse_rep_MP(Y, D, L):\n",
    "    \"\"\"\n",
    "    :param Y: This is a (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is a (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional vectors. Each column vector must have already been normalized.\n",
    "    :param L: This is an integer satisfying 0 < L <= K representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Runs in O( N K L ) time.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    assert d == d1, f\"The dimensions dont add up: Y.shape = {Y.shape} and D.shape = {D.shape}\" # Make sure the dimensions match up\n",
    "\n",
    "    A = np.zeros((K, N)) # Get our Sparse Representation Matrix\n",
    "\n",
    "    for j in range(N):  # Iterate over all of the N given signal vectors Y[:,j].\n",
    "\n",
    "        alpha = np.zeros(K)  # Initialize the sparse representation vector (will be a column vector in A)\n",
    "        r_vec = Y[:, j] - np.dot(D, alpha)  # Initialize the \"residual\" vector\n",
    "\n",
    "        for i in range(L): # Repeat until we utilize L atoms, or no more are needed\n",
    "            position_coeff_error = []\n",
    "\n",
    "            for k in range(K): # Find the best atom, D[:,k]\n",
    "\n",
    "                atom = D[:, k]\n",
    "\n",
    "                # Project the residual vector r_vec down to the linear subspace defined by the atom\n",
    "                coeff = np.inner(r_vec, atom)\n",
    "                error = np.linalg.norm(r_vec - coeff * atom)\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2]) # Find the atom whose linear subspace is closest to the residual vector r_vec\n",
    "\n",
    "            if np.abs(coeff) < 1e-6: #If the coefficient is too small, we don't add it and instead end the iteration\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                alpha[position] += coeff # Update the sparse representation vector, alpha\n",
    "                r_vec -= coeff * D[:, position] # Update the residual vector, r_vec\n",
    "\n",
    "        A[:, j] = alpha # Insert the sparse representation vector alpha into the matrix A\n",
    "\n",
    "    return A\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "def find_sparse_rep_OMP(Y, D, L):\n",
    "    \"\"\"\n",
    "    Find the sparse representation of the given signals Y over the dictionary D using the Orthogonal Matching Pursuit\n",
    "    algorithm.\n",
    "    Runs in O( N K L^2 ) time.\n",
    "\n",
    "    :param Y: A (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: A (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param L: An integer representing the maximum number of atoms which can be used in a sparse representation.\n",
    "\n",
    "    Note that we need N > K > d >= L\n",
    "\n",
    "    :return: A, a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "\n",
    "    # Initialize the sparse representation matrix A\n",
    "    A = np.zeros((K, N))\n",
    "\n",
    "    # Iterate over all of the N given signal vectors Y[:,j].\n",
    "    for j in range(N):\n",
    "\n",
    "        # Initialize the set of indices for the selected atoms\n",
    "        idx_set = set()\n",
    "\n",
    "        # Repeat until we utilize L atoms, or no more are needed\n",
    "        for i in range(L):\n",
    "\n",
    "            # Find the remaining unused atoms\n",
    "            remaining_atoms = set(range(K)).difference(idx_set)\n",
    "\n",
    "            # Initialize a list to store the coefficients and errors for each candidate atom\n",
    "            position_coeff_error = []\n",
    "\n",
    "            # Iterate over the remaining unused atoms and calculate the projection error for each\n",
    "            for k in remaining_atoms:\n",
    "                # Create the subspace basis from the remaining unused atoms plus the current candidate atom\n",
    "                subspace_basis = D[:, list(idx_set) + [k]]\n",
    "\n",
    "                # Solve for the coefficients of the projection\n",
    "                coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "                # Calculate the projected vector\n",
    "                projected = np.dot(subspace_basis, coeff)\n",
    "\n",
    "                # Calculate the error between the original signal and the projection\n",
    "                error = np.linalg.norm(Y[:, j] - projected)\n",
    "\n",
    "                # Store the position, coefficients, and error in the list\n",
    "                position_coeff_error.append((k, coeff, error))\n",
    "\n",
    "            # Select the candidate atom with the minimum projection error\n",
    "            position, coeff, error = min(position_coeff_error, key=lambda x: x[2])\n",
    "\n",
    "            # Add the selected atom to the set of indices for the selected atoms\n",
    "            idx_set.add(position)\n",
    "\n",
    "        # Create the final subspace basis from the selected atoms\n",
    "        subspace_basis = D[:, list(idx_set)]\n",
    "\n",
    "        # Solve for the coefficients of the sparse representation using the selected atoms\n",
    "        coeff = np.linalg.lstsq(subspace_basis, Y[:, j], rcond=None)[0]\n",
    "\n",
    "        # Initialize the sparse representation vector alpha\n",
    "        alpha = np.zeros(K)\n",
    "\n",
    "        # Insert the computed coefficients into the sparse representation vector alpha\n",
    "        for position, index in enumerate(idx_set):\n",
    "            alpha[index] = coeff[position]\n",
    "\n",
    "        # Insert the sparse representation vector alpha into the matrix A\n",
    "        A[:, j] = alpha\n",
    "\n",
    "        # Return the matrix of sparse representations\n",
    "    return A\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The strategy of making the worst represented signals the new atoms is shown to be optimal in\n",
    "https://cs.unibuc.ro//~pirofti/papers/Irofti16_AtomReplacement.pdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "def update_dictionary_kSVD(Y, D, A):\n",
    "    \"\"\"\n",
    "    Update the dictionary using the k-SVD algorithm. This\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors. Each column vector must have already been normalized.\n",
    "    :param A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "\n",
    "    :return: (D, A), where D is updated and optimized to the given  a (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes of the input matrices\n",
    "    (d, N) = Y.shape\n",
    "    (d1, K) = D.shape\n",
    "    (K1, N1) = A.shape\n",
    "\n",
    "    # Ensure that the dimensions match up\n",
    "    assert d == d1\n",
    "    assert K == K1\n",
    "    assert N == N1\n",
    "\n",
    "    # Iterate over every atom in the dictionary\n",
    "    unused_atoms = []\n",
    "    for k in tqdm(range(K)):\n",
    "        # Find the signal vectors, Y[:,j], whose sparse representation, A[:,j], have a non-zero entry in the k^th position. That is, they use the k^th atom.\n",
    "        non_zero_indices = np.nonzero(A[k, :])[0]\n",
    "\n",
    "        if len(non_zero_indices) == 0:\n",
    "            unused_atoms.append(k)\n",
    "\n",
    "        else:\n",
    "            # Get the k^th \"error matrix\"\n",
    "            E = Y - np.dot(D, A) + np.outer(D[:, k], A[k, :])\n",
    "\n",
    "            # Restrict the matrix to only those non-zero values. The resulting matrix should be KxL\n",
    "            E = E[:, non_zero_indices]\n",
    "\n",
    "            # Do the SVD (Singular Value Decomposition) step to the KxL matrix E\n",
    "            U, S, V = np.linalg.svd(E, full_matrices=False)\n",
    "\n",
    "            #print(f'For the k={k} atom, E={E}, and non_zero_indices = {non_zero_indices}')\n",
    "\n",
    "            # Update the k^th atom, D[:, k], and the k^th coefficients in the sparse representation, A[k, :].\n",
    "            # Note: The k-SVD algorithm also converges when run in parallel, only updating the matrix D at the end. However running the algorithm in series, updating the atoms and coefficients after each step, produces more robust results and typically requires more than four times as long to converge.\n",
    "            D[:, k] = U[:, 0]\n",
    "            A[k, non_zero_indices] = S[0] * V[0, :]\n",
    "\n",
    "    # Replace the unused atoms with the worst represented sample vectors\n",
    "    E = Y - np.dot(D, A)\n",
    "    errors = []\n",
    "    for j in range(N):\n",
    "        errors.append((j, np.linalg.norm(E[:,j])))\n",
    "    errors.sort(key = lambda x: -x[1])\n",
    "\n",
    "    num_unused = len(unused_atoms)\n",
    "    for i in range(num_unused):\n",
    "        D[:, unused_atoms[i]] = Y[:, errors[i][0]]\n",
    "\n",
    "\n",
    "    return (D, A)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "[(-1, 5), (4, 3), (1, 2)]"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [(1,2), (4,3), (-1, 5)]\n",
    "a.sort(key = lambda x: -x[1])\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "class DictionaryLearner:\n",
    "\n",
    "    def __init__(self, L, K, sampler = None, algo = None, Dictionary = None):\n",
    "        self.L = L # The maximum number of atoms a sparse representation can use\n",
    "        self.K = K # The size of the dictionary\n",
    "        self.Dictionary = Dictionary # The initial guesses for the dictionary\n",
    "        self.sampler = sampler\n",
    "        self.select_algorithm(algo)\n",
    "        self.errors = []\n",
    "\n",
    "        self.update_dictionary_kSVD = update_dictionary_kSVD\n",
    "        self.update_step()\n",
    "\n",
    "    def set_sampler(self, sampler):\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def set_initial_dictionary(self, D):\n",
    "        self.Dictionary = D\n",
    "\n",
    "    def select_algorithm(self, algo):\n",
    "        if algo == 'MP':\n",
    "            self.sparse_rep = find_sparse_rep_MP\n",
    "        elif algo == 'OMP':\n",
    "            self.sparse_rep = sparse_rep = find_sparse_rep_OMP\n",
    "\n",
    "        else:\n",
    "            self.sparse_rep = None\n",
    "\n",
    "\n",
    "\n",
    "    def update_step(self, inner_loop = 1, use_orig = False):\n",
    "        def update_dictionary(Y, Y_orig, D, A):\n",
    "            for i in range(inner_loop):\n",
    "                if use_orig:\n",
    "                    (D, A) = self.update_dictionary_kSVD(Y_orig, D, A)\n",
    "                else:\n",
    "                    (D,A) = self.update_dictionary_kSVD(Y, D, A)\n",
    "            return (D,A)\n",
    "        self.update_dictionary = update_dictionary\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def sparse_dictionary_learning(self, iters=10, output = True):\n",
    "    \"\"\"\n",
    "    This algorithm finds a (d x K) matrix D (the dictionary) and a (K x N) matrix A (the sparse representation) which minimise the L2 distance between Y and D A, ie, minimise ||Y - D A ||, subject to the constraint that each column of A has at most L non-zero elements.\n",
    "\n",
    "    :param Y: This is the (d x N) matrix representing the N different d-dimensional given signals.\n",
    "    :param K: An integer representing the size of the dictionary.\n",
    "    :param L: An integer representing the maximum number of \"atoms\", D[:, k], in the dictionary that each sparse representation vector, A[:, i], can use.\n",
    "\n",
    "    Note: This algorithm is written under the assumption that: 0 < L < d < K < N\n",
    "\n",
    "    :param D_initial: This is the initial guess for the (d x N) matrix D. If not None, the columns of this matrix must be unit length.\n",
    "    :param algo: This is a string defining the sparse representation algorithm. Either algo = 'OMP' for Orhtogonal Matching Pursuit, or algo = 'MP' for Matching Pursuit.\n",
    "    :param iters: The number of iterations this will run for\n",
    "    :param with_errors: A boolean which determines if the output includes the list of the error values at each step of the iteration.\n",
    "    :param samples: This tells us the number of random samples to take from the training data Y at each step\n",
    "\n",
    "    :return: (D, A, errors)\n",
    "        D: This is the (d x K) matrix representing the dictionary of K different atoms, where the atoms are d-dimensional\n",
    "    vectors.\n",
    "        A: This is the (K x N) matrix of the N different K-dimensional sparse representations of the columns of Y.\n",
    "        errors: This is an optional output. It is the list of the error values at each step of the iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure we have the proper stuff defined\n",
    "    assert self.sparse_rep != None\n",
    "\n",
    "    # Get the internal variables for ease\n",
    "    K = self.K\n",
    "    L = self.L\n",
    "    sampler = self.sampler\n",
    "    D = self.Dictionary\n",
    "    sparse_rep = self.sparse_rep\n",
    "    update_dictionary = self.update_dictionary\n",
    "\n",
    "    # Get Initial Dictionary if there is none\n",
    "    if D == None:\n",
    "        (Y, _) = sampler.sample()\n",
    "        N = len(Y[0, :])\n",
    "        D = Y[:, random.sample(range(N), k=K)]\n",
    "        D = D / np.linalg.norm(D, axis=0)\n",
    "\n",
    "    for step in range(iters):\n",
    "\n",
    "        # Get the batch of random samples\n",
    "        (Y, Y_orig) = sampler.sample()\n",
    "\n",
    "        # Find the Sparse Representations\n",
    "        A = sparse_rep(Y, D, L)\n",
    "\n",
    "        # Record the error\n",
    "        error = np.linalg.norm(Y - np.dot(D, A))\n",
    "        self.errors.append(error)\n",
    "\n",
    "        # Update the Dictionary\n",
    "        (D, A) = update_dictionary(Y, Y_orig, D, A)\n",
    "\n",
    "    # Record the error one last time\n",
    "    A = sparse_rep(Y, D, L)\n",
    "    error = np.linalg.norm(Y - np.dot(D, A))\n",
    "    self.errors.append(error)\n",
    "\n",
    "    # Update Dictionary\n",
    "    self.Dictionary = D\n",
    "\n",
    "    if output:\n",
    "        return D\n",
    "\n",
    "DictionaryLearner.sparse_dictionary_learning = sparse_dictionary_learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/200 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e0bb4d3b2814930b4a0f605a351e7b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([[-8.98365002e-02, -4.51697325e-02,  3.00000000e+01, ...,\n        -4.23095501e-02, -7.99130567e-02,  3.79506152e-02],\n       [-8.70033578e-02, -8.85272143e-02,  3.20000000e+01, ...,\n        -6.99302622e-02, -8.64109105e-02,  6.35943380e-02],\n       [-1.00277890e-01, -7.62751931e-02,  4.20000000e+01, ...,\n        -7.62458166e-02, -9.24856800e-02,  1.00612193e-01],\n       ...,\n       [-4.32255882e-02, -1.45981357e-01,  0.00000000e+00, ...,\n        -5.29897820e-02, -8.04382065e-02, -2.33725764e-02],\n       [-5.08526336e-02, -2.41953690e-02,  2.00000000e+00, ...,\n        -8.09548029e-02, -8.84516495e-02,  2.21627315e-02],\n       [-5.02708081e-02, -1.10662995e-01,  1.20000000e+01, ...,\n        -8.88142468e-02, -9.98732353e-02,  7.05429706e-02]])"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = Sampler(paths = ['dinner.jpg'])\n",
    "learner = DictionaryLearner(5, 200, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 1, output = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "def image_reconstruction(self, path):\n",
    "\n",
    "    # Get internal stuff for ease of use\n",
    "    D = self.Dictionary\n",
    "    patch_shape = self.sampler.patch_shape\n",
    "    patch_size = patch_shape[0]\n",
    "    L = self.L\n",
    "\n",
    "    img = laod_image(path)\n",
    "    large_shape = img.shape\n",
    "    num_rows, num_cols = large_shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    pbar = tqdm(total=num_patches_rows*num_patches_cols)\n",
    "\n",
    "    # Loop over all patches in the image\n",
    "    for i in range(num_patches_rows):\n",
    "        for j in range(num_patches_cols):\n",
    "            # Extract the patch from the image\n",
    "            patch = img[i:i+patch_size, j:j+patch_size, :]\n",
    "\n",
    "            # Compute the sparse coding of the patch\n",
    "            sparse_patch_code = self.sparse_rep(patch.flatten().reshape(-1,1), D, L)\n",
    "            recon_patch = np.dot(D, sparse_patch_code)\n",
    "            recon_patch = recon_patch.reshape(patch_shape)\n",
    "\n",
    "            # Add the reconstructed patch to the reconstructed image\n",
    "            recon_img[i:i+patch_size, j:j+patch_size, :] += recon_patch\n",
    "            count[i:i+patch_size, j:j+patch_size, :] += 1\n",
    "\n",
    "            # Increment the counter variable and update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    pbar.close()\n",
    "\n",
    "    # Average the pixel values at each pixel to get the final reconstructed image\n",
    "    recon_img /= count\n",
    "\n",
    "    # Convert the reconstructed image to uint8\n",
    "    recon_img = np.clip(recon_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return recon_img\n",
    "\n",
    "DictionaryLearner.image_reconstruction = image_reconstruction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 37601280 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\2902850806.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Load the image\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'dinner.jpg'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIMREAD_COLOR\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Resize the image to 400x300 pixels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mimg_resized\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m400\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m300\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minterpolation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mINTER_AREA\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:73: error: (-4:Insufficient memory) Failed to allocate 37601280 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('dinner.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Resize the image to 400x300 pixels\n",
    "img_resized = cv2.resize(img, (400, 300), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Convert the resized image to grayscale\n",
    "img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Save the grayscale image as 'small_gray_dinner.png'\n",
    "cv2.imwrite('small_gray_dinner.png', img_gray, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "(300, 400)"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = laod_image('small_gray_dinner.jpg')\n",
    "img.shape[:2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sam = Sampler(paths = ['small_gray_dinner.jpg'], patch_shape=np.array([8,8]), num_samples=150 )\n",
    "learner = DictionaryLearner(5, 100, sampler=sam, algo = 'OMP')\n",
    "learner.sparse_dictionary_learning(iters = 1, output = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/115149 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccbcd774d53449a9a4f46e6c16d1e00a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\812262737.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mpath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'small_dinner.jpg'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mrecon_img\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_reconstruction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecon_img\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwaitKey\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\2421907095.py\u001B[0m in \u001B[0;36mimage_reconstruction\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m             \u001B[1;31m# Compute the sparse coding of the patch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m             \u001B[0msparse_patch_code\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_rep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m             \u001B[0mrecon_patch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msparse_patch_code\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m             \u001B[0mrecon_patch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrecon_patch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpatch_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\1671544788.py\u001B[0m in \u001B[0;36mfind_sparse_rep_OMP\u001B[1;34m(Y, D, L)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;31m# Ensure that the dimensions match up\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[1;32massert\u001B[0m \u001B[0md\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0md1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;31m# Initialize the sparse representation matrix A\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "path = 'small_dinner.jpg'\n",
    "recon_img = learner.image_reconstruction(path)\n",
    "\n",
    "cv2.imshow(recon_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "(384, 1)"
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.flatten().reshape(-1,1).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\1662819167.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mlearner\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDictionaryLearner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mselect_alorithm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'MP'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mlearner\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_rep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mY\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "def reconstruct_image(D, img, patch_size, alpha):\n",
    "    # Compute the number of patches in the image\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "    num_patches_rows = num_rows - patch_size + 1\n",
    "    num_patches_cols = num_cols - patch_size + 1\n",
    "\n",
    "    # Initialize the reconstructed image\n",
    "    recon_img = np.zeros(img.shape, dtype=np.float32)\n",
    "    count = np.zeros(img.shape, dtype=np.float32)\n",
    "\n",
    "    # Loop over all patches in the image\n",
    "    for i in tqdm(range(num_patches_rows)):\n",
    "        for j in range(num_patches_cols):\n",
    "            # Extract the patch from the image\n",
    "            patch = img[i:i+patch_size, j:j+patch_size, :]\n",
    "\n",
    "            # Compute the sparse coding of the patch\n",
    "            code = find_sparse_rep_OMP(Y, D, L)\n",
    "            sparse_code(D, patch, alpha)\n",
    "\n",
    "        # Reconstruct the patch using the dictionary\n",
    "        recon_patch = np.dot(D, code)\n",
    "        recon_patch = np.reshape(recon_patch, (patch_size, patch_size, 3))\n",
    "\n",
    "        # Add the reconstructed patch to the reconstructed image\n",
    "        recon_img[i:i+patch_size, j:j+patch_size, :] += recon_patch\n",
    "        count[i:i+patch_size, j:j+patch_size, :] += 1\n",
    "\n",
    "# Average the pixel values at each pixel to get the final reconstructed image\n",
    "recon_img /= count\n",
    "\n",
    "# Convert the reconstructed image to uint8\n",
    "recon_img = np.clip(recon_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "return recon_img\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([1,2,3]).prod()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.05992862, -0.01217082, -0.01924014,  0.0360319 , -0.00776401,\n        -0.000524  ,  0.14573281,  0.07641563],\n       [-0.18572422,  0.14079179, -0.15667047,  0.2305574 ,  0.04327394,\n         0.03192766, -0.03948167,  0.15574063],\n       [-0.18094431,  0.03454035,  0.05829101, -0.04971573, -0.02696382,\n        -0.13489656,  0.09165429, -0.09473357],\n       [-0.07280259, -0.0614746 , -0.0841094 , -0.10062964,  0.03619999,\n        -0.07039527,  0.01951222,  0.04212763],\n       [-0.01718095, -0.02416182,  0.14357363, -0.06101194, -0.0752874 ,\n         0.05919809,  0.18025043, -0.06981907],\n       [ 0.04946283, -0.00567512, -0.03728039, -0.01652367, -0.06759748,\n        -0.02250607, -0.03298199, -0.02765604],\n       [ 0.06038713, -0.06817364,  0.05721233,  0.06235531,  0.09877378,\n         0.06874567,  0.0978708 ,  0.12555003],\n       [ 0.07603313, -0.04014293, -0.1132591 ,  0.18838865, -0.01803408,\n         0.15091138,  0.0526451 , -0.10075915]])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 0.1, np.array([8,8]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\2486947686.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
