{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Thursday To-Do List:\n",
    "~~~1. Get more pictures for testing~~~\n",
    "~~~2. Figure out the proper evaluation metrics (signal/noise, etc...)~~~\n",
    "3. Make a seperate method for evaluation\n",
    "4. Do statistical tests to prove SPIR is accurate\n",
    "5. Make a method/function for testing and graphing results and saving images\n",
    "6. Make a default list of parameters, make the parameters option optional, make it easier to change\n",
    "7. Show that/if replacing unused atoms gives better results\n",
    "8. Run tests on other toggles in the algorithm\n",
    "9. Test you crazy idea about rescaling the sparse reps to acount for stuff in the demosaicing process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "The simplest and most intuitive evalutation metric is the Mean Square Error ($MSE$)\n",
    "$$MSE = \\frac{1}{d}|| y - x ||_2^2$$\n",
    "between a signal $y$ and its approximation $x$.\n",
    "However a standard in the industry is to use Peak Signal to Noise Ratio ($PSNR$)\n",
    "$$ PSNR = 10 \\log_{10}\\Big( \\frac{ ||y||_\\infty^2}{ \\frac{1}{d}||y - x ||_2^2}\\Big) $$\n",
    "which since the majority of signals will have $||y||_\\infty \\approx 255$, the $PSNR$ has a logrithmic relation to the $MSE$, and therefore contain an identical amount of information.\n",
    "\n",
    "Another standard evaluation metric is the Structural Similarity Index Measure ($SSIM$),\n",
    "$$ SSIM(y, x) = l(y, x) c(y, x) s(y,x), $$\n",
    "which is the product of three distortion measurements.\n",
    "Luminance Distortion\n",
    "$$ l(y,x) = \\frac{2 \\mu_y \\mu_x + C_l}{\\mu_y^2 + \\mu_x^2 + C_l} $$\n",
    "Contrast Distortion\n",
    "$$ c(y,x) = \\frac{2 \\sigma_y \\sigma_x + C_c}{\\sigma_Y ^2 + \\sigma_x^2 + C_c} $$\n",
    "Structural Comparison\n",
    "$$ s(y,x) = \\frac{ \\sigma_{yx} ++ C_s}{ \\sigma_Y \\sigma_x + C_s} $$\n",
    "where\n",
    "$$\\mu_x = \\frac{1}{d} \\sum x^{(i)} $$\n",
    "$$\\sigma_x^2 = \\frac{1}{d} \\sum(x^{(i)} - \\mu_x)^2 $$\n",
    "$$\\sigma_{xy} = \\frac{1}{d} \\sum (x^{(i)} - \\mu_x)(y^{(i)} - \\mu_y) $$\n",
    "\n",
    "These metrics give an idea of what area an image reconstruction is doing better or worse on.\n",
    "\n",
    "We will measure all of these qnatities, plus run-time (as a proxy for \"compute\") and gain (the improvement of these metrics). We will typically only display the $PSNR$, however when a more indepth analysis is called for, we will display the rest.\n",
    "\n",
    "*A comparison of these metrics is found in here https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/iet-ipr.2012.0489"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%run Classes.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "paths = ['Compressed Images/cheese_board.jpg', 'Compressed Images/chicken_n_beans.jpg', 'Compressed Images/persimmon_tomato_salad.jpg', 'Compressed Images/octopus.jpg']\n",
    "new_path = 'Reconstructed Images/tea_eggs'\n",
    "path_orig = 'Compressed Images/tea_eggs.jpg'\n",
    "path_corrupted = 'Compressed Images/tea_eggs_corrupted.jpg'\n",
    "\n",
    "sam = Sampler(paths = paths, patch_shape = np.array([8,8]), num_samples = 500)\n",
    "sam.add_filter('noise', std = 100)\n",
    "learner = DictionaryLearner(L=2, K=200, sampler=sam, algo = 'OMP')\n",
    "learner.update_step(use_orig=True)\n",
    "\n",
    "img_orig = load_image(path_orig)\n",
    "img_corrupt = sam.filter(img_orig)\n",
    "\n",
    "cv2.imwrite(path_corrupted, img_corrupt)\n",
    "\n",
    "cv2.imshow(\"Original Image\", img_orig)\n",
    "cv2.imshow(\"Corrupted Image\", img_corrupt)\n",
    "cv2.moveWindow(\"Corrupted Image\", img_orig.shape[1], 0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f64caf25150f4a5f956c6c57870cb7fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Complete\n"
     ]
    }
   ],
   "source": [
    "D = learner.sparse_dictionary_learning(iters=1, output=True)\n",
    "print(\"Dictionary Complete\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5519 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85936ebf506942bcb0d105fb20277333"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raino\\GitHub\\Sparse-Dictionary-Learning\\Classes.py:579: RuntimeWarning: invalid value encountered in floor_divide\n",
      "  recon_img = recon_img // count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Complete\n",
      "Error Est. = 60.32252505383432\n"
     ]
    }
   ],
   "source": [
    "(recon, error) = learner.SPIR(path=path_corrupted, percent=.2, min_count=1, apply_filter=True)\n",
    "print(f'Reconstruction Complete')\n",
    "print(f'Error Est. = {error}')\n",
    "\n",
    "cv2.imshow(\"Original Image\", img_orig)\n",
    "cv2.imshow(\"Corrupted Image\", img_corrupt)\n",
    "cv2.moveWindow(\"Corrupted Image\", img_orig.shape[1], 0)\n",
    "\n",
    "cv2.imshow('Reconstructed Image', recon)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters = 0, Error = 52.24964272800685\n"
     ]
    }
   ],
   "source": [
    "print(f'Iters = 0, Error = {error}')\n",
    "#print(f'Iters = 1, Error = 6.0670')\n",
    "#print(f'Iters = 2, Error = 5.3670')\n",
    "#print(f'Iters = 10, Error = {error}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cv2.imshow('temp image', recon)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def new_test_process(test_name, N=300, K=100, I=5, L=4, P=8, save_dic = False, generate_graph = False, variabel = None):\n",
    "    print(f\"Test: {test_name}\")\n",
    "    print(f\"Params: N = {N}, K = {K}, I = {I}, L = {L}, P = {P}\")\n",
    "\n",
    "    patch_shape = np.array([P, P])\n",
    "\n",
    "    sam = Sampler(paths=paths, patch_shape=patch_shape, num_samples=N)\n",
    "    learner = DictionaryLearner(L=L, K=K, sampler=sam, algo='OMP')\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    D = learner.sparse_dictionary_learning(iters=I, output=True)\n",
    "\n",
    "    (recon, error) = learner.SPIR(path=path, percent=percent, min_count=min_count)\n",
    "\n",
    "    # Calculate the run time\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    # Save the reconstruction\n",
    "    correct_path = 'Reconstructed Images/' + test_name + 'N' + str(N) + 'K' + str(K) + 'I' + str(I) + 'L' + str(L) + 'P' + str(P) + '.jpg'\n",
    "    cv2.imwrite(correct_path, recon)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Error = {error}, Run Time = {run_time}\")\n",
    "\n",
    "    # Save the results\n",
    "    #data[(N, K, I, L, P)] = [error, run_time]\n",
    "\n",
    "    with open('Graphs/' + test_name + '_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    data[(N, K, I, L, P)] = [error, run_time]\n",
    "\n",
    "    with open('Graphs/' + test_name + '_data.pkl', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    if save_dic:\n",
    "\n",
    "        with open('Graphs/' + test_name + '_dictionaries.pkl', 'rb') as f:\n",
    "            dictionaries = pickle.load(f)\n",
    "\n",
    "        dictionaries[(N, K, I, L, P)] = D\n",
    "\n",
    "        with open('Graphs/' + test_name + '_dictionaries.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    if generate_graph:\n",
    "        xs =[x[variabel] for x in list(data.keys())]\n",
    "        es = [y[0] for y in list(data.values())]\n",
    "        ts = [y[1] for y in list(data.values())]\n",
    "\n",
    "\n",
    "        # create the figure and first axis\n",
    "        fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # create the first line and first y-axis\n",
    "        ax1.plot(xs, es, linestyle='-.', marker='s', color='blue', label='Error Est.')\n",
    "\n",
    "        X_label = ['N', 'K', 'I', 'L', 'P']\n",
    "        X_label = X_label[variabel]\n",
    "        ax1.set_xlabel(X_label + ' Value')\n",
    "\n",
    "        ax1.set_ylabel('Error Est.')\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        ax2.plot(xs, ts, linestyle='--', marker='^', color='green', label = 'Run Time')\n",
    "\n",
    "        # rotate and adjust second y-axis label\n",
    "        ax2.yaxis.set_label_coords(1.1, 0.5)\n",
    "        ax2.set_ylabel('Run Time', rotation=-90, labelpad=10)\n",
    "\n",
    "        ax1.set_title('Run Time and Error Est. with varying ' + X_label + ' values')\n",
    "\n",
    "        # combine legends from both axes\n",
    "        lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "        lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines_1 + lines_2, labels_1 + labels_2)\n",
    "\n",
    "        # save the graph as a PNG file\n",
    "        plt.savefig('Graphs/' + test_name + '.png')\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "img_orig = load_image('Compressed Images/cheese_board.jpg')\n",
    "img_recon = load_image('Reconstructed Images/cheese_boardL16.jpg')\n",
    "\n",
    "img_diff = np.abs(img_orig.astype(int) - img_recon.astype(int))\n",
    "img_diff = np.clip(img_diff, 0, 255).astype(np.uint8)\n",
    "\n",
    "cv2.imshow('Original', img_orig)\n",
    "cv2.imshow('Recon.', img_recon)\n",
    "\n",
    "cv2.imshow('difference', img_diff)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 57,  76,  78, ...,  27,  27,  27],\n       [ 40,  68,  80, ...,  34,  33,  34],\n       [ 26,  61,  76, ...,  39,  39,  40],\n       ...,\n       [102, 106, 107, ..., 137, 123, 125],\n       [106, 102, 107, ..., 112, 114, 116],\n       [106, 109, 122, ..., 114, 128, 114]], dtype=uint8)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_orig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  1,   0,  69, ...,   0,   0,   1],\n       [  0,   0,  75, ...,   1,   0,   0],\n       [  1,   0,  64, ...,   1,   2,   0],\n       ...,\n       [  1,   0,   4, ..., 125, 134,   0],\n       [  0,   3,   1, ..., 120,   0,   0],\n       [  0,   1,   0, ..., 114,   2,   0]], dtype=uint8)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_recon"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[200, 180, 247, ..., 229, 229, 230],\n       [216, 188, 251, ..., 223, 223, 222],\n       [231, 195, 244, ..., 218, 219, 216],\n       ...,\n       [155, 150, 153, ..., 244,  11, 131],\n       [150, 157, 150, ...,   8, 142, 140],\n       [150, 148, 134, ...,   0, 130, 142]], dtype=uint8)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_recon - img_orig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_orig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "-56"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(img_recon[0,0]) - int(img_orig[0,0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "247"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_diff.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  Reconstructed Path  Original Path  Corrupted Path  Partial or Full  \\\n1                 hi            NaN             NaN              NaN   \n\n   Run Time  MSE  PSNR  SSIM  Luminance Dist.  Contrast Dist.  ...  SSIM Gain  \\\n1        10  NaN   NaN   NaN              NaN             NaN  ...        NaN   \n\n   Luminance Dist. Gain  Contrast Dist. Gain  Structural Comp. Gain  param: K  \\\n1                   NaN                  NaN                    NaN       NaN   \n\n   param: N  param: Iters  param: L  param: patch_shape  param: other  \n1       NaN           NaN       NaN                 NaN           NaN  \n\n[1 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Reconstructed Path</th>\n      <th>Original Path</th>\n      <th>Corrupted Path</th>\n      <th>Partial or Full</th>\n      <th>Run Time</th>\n      <th>MSE</th>\n      <th>PSNR</th>\n      <th>SSIM</th>\n      <th>Luminance Dist.</th>\n      <th>Contrast Dist.</th>\n      <th>...</th>\n      <th>SSIM Gain</th>\n      <th>Luminance Dist. Gain</th>\n      <th>Contrast Dist. Gain</th>\n      <th>Structural Comp. Gain</th>\n      <th>param: K</th>\n      <th>param: N</th>\n      <th>param: Iters</th>\n      <th>param: L</th>\n      <th>param: patch_shape</th>\n      <th>param: other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Reconstructed Path', 'Original Path', 'Corrupted Path', 'Partial or Full',  'Run Time', 'MSE', 'PSNR', 'SSIM', 'Luminance Dist.', 'Contrast Dist.', 'Structural Comp.', 'MSE Gain', 'PSNR Gain', 'SSIM Gain', 'Luminance Dist. Gain', 'Contrast Dist. Gain', 'Structural Comp. Gain',  'param: K', 'param: N', 'param: Iters', 'param: L', 'param: patch_shape', 'param: other'])\n",
    "df.loc[1] = {'Reconstructed Path':'hi', 'Run Time': 10}\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.max()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,4,-2,0]).astype(int)\n",
    "(a**2).sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.float64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('EVALUATION_METRICS.csv')\n",
    "type(df['param: Iters'][2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 1.5       ],\n       [1.5       , 2.33333333]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,4])\n",
    "np.cov(a, b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 0., 1.])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((a - a.mean())**2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6666666666666666"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.std()**2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6666666666666666"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.var()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 1.5       ],\n       [1.5       , 2.33333333]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(a, b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((a - a.mean() ) * (b - b.mean()) ).sum()/3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.33333333, 0.66666667, 1.        ])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.astype(int)\n",
    "a = a / 3\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
